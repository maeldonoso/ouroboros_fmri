{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ouroboros fMRI: Predicting human brain activity with machine learning models**\n",
    "\n",
    "#### Version: 10th March 2021\n",
    "\n",
    "==============================================================================================\n",
    "\n",
    "Project developed by Maël Donoso, Ph.D. in Cognitive and Computational Neuroscience. Affiliations: Ouroboros Neurotechnologies (https://ouroboros-neurotechnologies.com/), Institut Lémanique du Cerveau (https://institut-cerveau.ch/), Policlinique Ostéopathique de Lausanne (https://policlinique-osteopathique-lausanne.ch/). \n",
    "\n",
    "The first version of this project (17th February 2021) was presented as a Capstone Project for the COS in Applied Data Science: Machine Learning of the EPFL Extension School (https://www.extensionschool.ch/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "\n",
    "This project is presented through six Notebooks:\n",
    "\n",
    "*01: Data Analysis*\n",
    "\n",
    "***02: Classification* (all classification models except neural networks)**\n",
    "\n",
    "*03: Neural Networks*\n",
    "\n",
    "*04: Regression*\n",
    "\n",
    "*05: Results*\n",
    "\n",
    "*06: Complements*\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 02\n",
    "\n",
    "# **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Introduction to Classification**\n",
    "\n",
    "### 1.1 Objective\n",
    "\n",
    "The objective of this project is to address the general question: **Can we train machine learning models to recognize and predict brain activity?** This problem can be seen both as a classification and a regression challenge. \n",
    "\n",
    "As a classification challenge, the specific question can be defined this way: **After training classification models on a set of statistical maps associated with specific conditions, can we accurately classify a set of new, unseen and unlabelled statistical maps?** In our case, the conditions of interest are the 3 levels of 'goal conduciveness', and the target variable can take 3 possible values: good, neutral, bad. Therefore, our approach will be to fit a series of classification models on a train set of statistical maps, each map associated with one of the 3 possible target values, and then to use these models to classify a test set of new, unseen and unlabelled statistical maps. Then, we will verify how often the models have correctly classified the new statistical maps, compared to the level of chance, which is 33% since we have 3 equally distributed possible target values. \n",
    "\n",
    "### 1.2 Models\n",
    "\n",
    "We will use a variety of classification models and fine-tune their hyperparameters when relevant: **k-NN**, **decision tree**, **random forest**, **SVM**, **logistic regression**, **dense neural network**, **convolutional neural network**. This Notebook is dedicated to all classification models except the neural networks, while the next Notebook is dedicated to neural networks exclusively. By default, we will fit the models using the statistical maps with the original voxel size, but if the computations are too heavy, the stastistical maps with the rescaled voxel sizes can also be selected in the data import section. \n",
    "\n",
    "### 1.3 Summary\n",
    "\n",
    "Here is a summary of the features and target variables in classification models and regression models: \n",
    "\n",
    "Classification models  | Regression models\n",
    "------------- | -------------\n",
    "*Features*: statistical maps  | *Features:* value of all voxels/clusters except the voxel/cluster of interest\n",
    "*Target*: condition of interest (good, neutral, bad)  | *Target:* value of the voxel/cluster of interest\n",
    "\n",
    "And here is a general overview of the major preprocessing, model training, model testing and model comparison steps in this project:\n",
    "\n",
    "Classification models (except neural networks)  | Classification models (neural networks)  | Regression models\n",
    "------------- | ------------- | -------------\n",
    "Rescale voxel size: optional  | Rescale voxel size: optional  | Rescale voxel size: optional\n",
    "Split into train+valid (X) and test (X_te) sets  | Split into train+valid (X) and test (X_te) sets  | Split into train+valid (X) and test (X_te) sets\n",
    "Flatten the arrays  | Keep the 3D arrays  |  Flatten the arrays\n",
    "Remove NaN or replace by zero  | Replace NaN by zero | Remove NaN or replace by zero\n",
    "Fine tuning: grid search with cross-validation  | Neural network training  | Fine tuning: split train+valid (X) into X_tr and X_va\n",
    "Model comparison: test accuracy  | Model comparison: test accuracy  | Model comparison: MSE\n",
    "Baseline: level of chance (33%)  | Baseline: level of chance (33%)  | Baseline: mean value of the voxel/cluster obtained from train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Rules and functions**\n",
    "\n",
    "In order to fine-tune our classification models, we will use a **grid search with cross-validation** strategy, with a 5-fold cross-validation. Since we work with a limited number of statistical maps, we will not always end up with one single best combination of hyperparameters. Sometimes, several combinations will show the maximum mean test score, and we should specify a **set of rules** to decide which hyperparameters to choose in this scenario. \n",
    "\n",
    "We will use the following set of rules, which seem reasonable: 1) When a parameter ranges clearly from simple to complex, for example the depth of a decision tree or the number of estimators in a random forest, **we take the simplest one as the optimal parameter**. 2) When a parameter refers to a general strategy, for example RBF vs linear kernel in SVM, or OVR vs multinomial strategy in logistic regression, **we take the strategy that shows the highest mean test score as the optimal parameter**. 3) When one of the best values is the default value of a parameter, for example C = 1 for SVM or logistic regression, **we take this default value as the optimal parameter**. 4) If the application of these rules remains insufficient to select a single solution, **we take the first of the remaining results**. Of course, if the grid search with cross-validation allows us to identify a clear winner, none of these rules apply and we take simply the combination of hyperparameters with the maximum mean test score. \n",
    "\n",
    "In the following cells, we define a series of functions that will be helpful throughout the Notebook to **display the results from our grid searches with DataFrames and graphs**, and to compute **confusion matrixes** to visualize the accuracy of our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to display the grid search results with a DataFrame. \n",
    "def train_valid_dataframe(grid_cv, model_name, parameter_name, second_parameter_name = '', third_parameter_name = ''):\n",
    "    cols = ['param_' + model_name + '__' + parameter_name, 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']\n",
    "    if second_parameter_name != '':\n",
    "        cols = ['param_' + model_name + '__' + second_parameter_name] + cols\n",
    "    if third_parameter_name != '':\n",
    "        cols = ['param_' + model_name + '__' + third_parameter_name] + cols\n",
    "    cv_results = pd.DataFrame(grid_cv.cv_results_)[cols]\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to display the grid search results with a graph. \n",
    "def train_valid_graph(plot_results, model_name, parameter_name):\n",
    "    plot_grid_parameter = eval('cv_results_' + model_name + '.param_' + model_name + '__' + parameter_name + '.values.astype(int)')\n",
    "    \n",
    "    # Plot the mean scores. \n",
    "    plt.plot(plot_grid_parameter, plot_results.mean_train_score, label = 'train', color = 'blue')\n",
    "    plt.plot(plot_grid_parameter, plot_results.mean_test_score, label = 'test', color = 'green')\n",
    "\n",
    "    # Plot the variance area. \n",
    "    plt.fill_between(plot_grid_parameter, \n",
    "                     plot_results.mean_train_score - plot_results.std_train_score,\n",
    "                     plot_results.mean_train_score + plot_results.std_train_score,\n",
    "                     alpha = 0.2, color = 'blue')\n",
    "    plt.fill_between(plot_grid_parameter, \n",
    "                     plot_results.mean_test_score - plot_results.std_test_score,\n",
    "                     plot_results.mean_test_score + plot_results.std_test_score,\n",
    "                     alpha = 0.2, color = 'green');\n",
    "\n",
    "    # Add marker for the best score. \n",
    "    idx_best_parameter = plot_results.mean_test_score.idxmax()\n",
    "    plt.scatter(plot_grid_parameter[idx_best_parameter], plot_results.mean_test_score.max(), marker = 'x', c = 'green', zorder = 10)\n",
    "\n",
    "    # Display title and labels. \n",
    "    plt.title('Optimal {}: {} with {:.1f}% accuracy'.format(parameter_name, plot_grid_parameter[idx_best_parameter], 100 * plot_results.mean_test_score[idx_best_parameter]))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.xticks(plot_grid_parameter)\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a Scikit-learn confusion matrix. \n",
    "def scikit_learn_confusion_matrix(y_te, y_pred):\n",
    "    # Compute the confusion matrix. \n",
    "    labels = ['good', 'neutral', 'bad']\n",
    "    matrix = confusion_matrix(\n",
    "        y_true = y_te,\n",
    "        y_pred = y_pred, \n",
    "        labels = labels\n",
    "    )\n",
    "\n",
    "    # Return confusion matrix as a DataFrame. \n",
    "    matrix_df = pd.DataFrame(data = matrix, columns = labels, index = labels)\n",
    "    matrix_df.columns.name = 'Predictions'\n",
    "    matrix_df.index.name = 'True class'\n",
    "    return matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate a custom confusion matrix. \n",
    "def custom_confusion_matrix(y_te, y_pred):\n",
    "    # Compute the confusion matrix. \n",
    "    pred_comparison = pd.DataFrame([y_te, y_pred], index = ['y_te', 'y_pred']).T\n",
    "    labels = ['good', 'neutral', 'bad']\n",
    "    matrix_df = pd.DataFrame()\n",
    "    for y_te_value in labels:\n",
    "        for y_pred_value in labels:\n",
    "            matrix_df.loc[y_te_value, y_pred_value] = np.sum((pred_comparison.y_te == y_te_value) & \n",
    "                                                             (pred_comparison.y_pred == y_pred_value))\n",
    "\n",
    "    # Return confusion matrix as a DataFrame. \n",
    "    matrix_df.columns.name = 'Predictions'\n",
    "    matrix_df.index.name = 'True class'\n",
    "    return matrix_df.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessed data path. \n",
    "preprocessed_data_path = '../ouroboros_fmri_preprocessed_data/'\n",
    "\n",
    "# Define the results path. If empty, the results will be saved in the current directory. \n",
    "results_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rescale mode. \n",
    "# 1: original data | 2, 3, 4: voxel size rescaled by a factor 2, 3 or 4. \n",
    "rescale_mode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data. \n",
    "with np.load(preprocessed_data_path + 'datasets_for_machine_learning.npz', allow_pickle = False) as npz_file:\n",
    "    data_dict = dict(npz_file.items())\n",
    "rescale_modes_list = ['', '_r2', '_r3', '_r4']\n",
    "    \n",
    "# Features of the train+valid dataset. \n",
    "X = data_dict['features_preprocessed' + rescale_modes_list[rescale_mode - 1] + '_tr']\n",
    "\n",
    "# Features of the test dataset. \n",
    "X_te = data_dict['features_preprocessed' + rescale_modes_list[rescale_mode - 1] + '_te']\n",
    "\n",
    "# Target variables. \n",
    "y = data_dict['target_tr']\n",
    "y_te = data_dict['target_te']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:    (120, 256007)\n",
      "X_te: (36, 256007)\n",
      "y:    (120,)\n",
      "y_te: (36,)\n"
     ]
    }
   ],
   "source": [
    "# Display the size of the arrays. \n",
    "print('X:   ', X.shape)\n",
    "print('X_te:', X_te.shape)\n",
    "print('y:   ', y.shape)\n",
    "print('y_te:', y_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. K-Nearest Neighbors (k-NN)**\n",
    "\n",
    "In the following cells, we **fine-tune, fit and compute predictions from a k-NN model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Grid search with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the set of values to explore. \n",
    "k_values = np.arange(1, 17, 1)\n",
    "k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'knn__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Create cross-validation object. \n",
    "grid_knn = {\n",
    "    'knn__n_neighbors': k_values\n",
    "}\n",
    "grid_cv_knn = GridSearchCV(pipe_knn, grid_knn, cv = 5, return_train_score = True, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Fit k-NN. \n",
    "grid_cv_knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.097183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.031319</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.046304</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.121906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.040612</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.062361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.069722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.084984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.084984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.445833</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.051623</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.443750</td>\n",
       "      <td>0.024296</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.464583</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_knn__n_neighbors  mean_train_score  std_train_score  mean_test_score  \\\n",
       "0                       1          1.000000         0.000000         0.408333   \n",
       "1                       2          0.935417         0.017922         0.441667   \n",
       "2                       3          0.925000         0.012148         0.466667   \n",
       "3                       4          0.650000         0.016925         0.441667   \n",
       "4                       5          0.552083         0.018634         0.533333   \n",
       "5                       6          0.333333         0.000000         0.483333   \n",
       "6                       7          0.389583         0.031319         0.466667   \n",
       "7                       8          0.404167         0.046304         0.450000   \n",
       "8                       9          0.416667         0.040612         0.475000   \n",
       "9                      10          0.466667         0.017922         0.500000   \n",
       "10                     11          0.427083         0.011411         0.491667   \n",
       "11                     12          0.460417         0.030477         0.533333   \n",
       "12                     13          0.445833         0.017922         0.450000   \n",
       "13                     14          0.466667         0.051623         0.500000   \n",
       "14                     15          0.443750         0.024296         0.508333   \n",
       "15                     16          0.464583         0.015590         0.491667   \n",
       "\n",
       "    std_test_score  \n",
       "0         0.061237  \n",
       "1         0.122474  \n",
       "2         0.061237  \n",
       "3         0.097183  \n",
       "4         0.061237  \n",
       "5         0.033333  \n",
       "6         0.066667  \n",
       "7         0.121906  \n",
       "8         0.062361  \n",
       "9         0.069722  \n",
       "10        0.084984  \n",
       "11        0.084984  \n",
       "12        0.061237  \n",
       "13        0.083333  \n",
       "14        0.061237  \n",
       "15        0.061237  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results with a DataFrame. \n",
    "cv_results_knn = train_valid_dataframe(grid_cv_knn, 'knn', 'n_neighbors')\n",
    "cv_results_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the results with a graph and mark the first best result. \n",
    "train_valid_graph(cv_results_knn, 'knn', 'n_neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test score with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.084984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_knn__n_neighbors  mean_train_score  std_train_score  mean_test_score  \\\n",
       "4                       5          0.552083         0.018634         0.533333   \n",
       "11                     12          0.460417         0.030477         0.533333   \n",
       "\n",
       "    std_test_score  \n",
       "4         0.061237  \n",
       "11        0.084984  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the results with the highest mean test score. \n",
    "best_results_knn = cv_results_knn[cv_results_knn.mean_test_score == cv_results_knn.mean_test_score.max()]\n",
    "best_results_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.061237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_knn__n_neighbors  mean_train_score  std_train_score  mean_test_score  \\\n",
       "4                      5          0.552083         0.018634         0.533333   \n",
       "\n",
       "   std_test_score  \n",
       "4        0.061237  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among these results, select the result with the lowest number of neighbors. \n",
    "best_result_knn = best_results_knn[best_results_knn.param_knn__n_neighbors == best_results_knn.param_knn__n_neighbors.min()]\n",
    "best_result_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get this number of neighbors. \n",
    "best_param_knn = best_result_knn.param_knn__n_neighbors.iloc[0]\n",
    "best_param_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_knn_optimal = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors = best_param_knn))\n",
    "])\n",
    "\n",
    "# Fit optimal k-NN. \n",
    "pipe_knn_optimal.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the test score. \n",
    "test_score_knn = pipe_knn_optimal.score(X_te, y_te)\n",
    "test_score_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Predictions and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'bad', 'neutral', 'neutral', 'bad', 'neutral', 'good',\n",
       "       'good', 'good', 'good', 'good', 'good', 'good', 'neutral', 'good',\n",
       "       'good', 'neutral', 'bad', 'good', 'good', 'good', 'good', 'good',\n",
       "       'good', 'good', 'bad', 'good', 'good', 'bad', 'bad', 'good',\n",
       "       'good', 'good', 'good', 'bad', 'bad'], dtype='<U7')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the predictions. \n",
    "y_pred_knn = pipe_knn_optimal.predict(X_te)\n",
    "y_pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_te</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_knn</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1        2        3    4        5     6     7        8   \\\n",
       "y_te        good  good  neutral  neutral  bad      bad  good  good  neutral   \n",
       "y_pred_knn   bad   bad  neutral  neutral  bad  neutral  good  good     good   \n",
       "\n",
       "                 9   ...       26       27   28   29    30    31       32  \\\n",
       "y_te        neutral  ...  neutral  neutral  bad  bad  good  good  neutral   \n",
       "y_pred_knn     good  ...     good     good  bad  bad  good  good     good   \n",
       "\n",
       "                 33   34   35  \n",
       "y_te        neutral  bad  bad  \n",
       "y_pred_knn     good  bad  bad  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the true and predicted target values. \n",
    "pred_comparison = pd.DataFrame([y_te, y_pred_knn], index = ['y_te', 'y_pred_knn']).T\n",
    "pred_comparison.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  good  neutral  bad\n",
       "True class                     \n",
       "good            8        1    3\n",
       "neutral        10        2    0\n",
       "bad             4        2    6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a Scikit-learn confusion matrix. \n",
    "confusion_matrix_knn = scikit_learn_confusion_matrix(y_te, y_pred_knn)\n",
    "confusion_matrix_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  good  neutral  bad\n",
       "True class                     \n",
       "good            8        1    3\n",
       "neutral        10        2    0\n",
       "bad             4        2    6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Security check: display a custom confusion matrix. \n",
    "custom_confusion_matrix_knn = custom_confusion_matrix(y_te, y_pred_knn)\n",
    "custom_confusion_matrix_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify if the two confusion matrixes are equal. \n",
    "confusion_matrix_knn.equals(custom_confusion_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The k-NN model performs better than the baseline of 33%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Decision tree**\n",
    "\n",
    "In the following cells, we **fine-tune, fit and compute predictions from a decision tree model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Grid search with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the set of values to explore. \n",
    "n_values = np.arange(1, 11, 1)\n",
    "n_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   31.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', None), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'dt__max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', None),\n",
    "    ('dt', DecisionTreeClassifier(criterion = 'gini', random_state = 0))\n",
    "])\n",
    "\n",
    "# Create cross-validation object. \n",
    "grid_dt = {\n",
    "    'dt__max_depth': n_values\n",
    "}\n",
    "grid_cv_dt = GridSearchCV(pipe_dt, grid_dt, cv = 5, return_train_score = True, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Fit decision tree. \n",
    "grid_cv_dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_dt__max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.080795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.121906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.014130</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.077280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_dt__max_depth  mean_train_score  std_train_score  mean_test_score  \\\n",
       "0                   1          0.575000         0.012148         0.508333   \n",
       "1                   2          0.783333         0.012148         0.508333   \n",
       "2                   3          0.920833         0.016925         0.508333   \n",
       "3                   4          0.983333         0.014130         0.516667   \n",
       "4                   5          1.000000         0.000000         0.466667   \n",
       "5                   6          1.000000         0.000000         0.466667   \n",
       "6                   7          1.000000         0.000000         0.466667   \n",
       "7                   8          1.000000         0.000000         0.466667   \n",
       "8                   9          1.000000         0.000000         0.466667   \n",
       "9                  10          1.000000         0.000000         0.466667   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.080795  \n",
       "1        0.121906  \n",
       "2        0.124722  \n",
       "3        0.077280  \n",
       "4        0.096465  \n",
       "5        0.096465  \n",
       "6        0.096465  \n",
       "7        0.096465  \n",
       "8        0.096465  \n",
       "9        0.096465  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results with a DataFrame. \n",
    "cv_results_dt = train_valid_dataframe(grid_cv_dt, 'dt', 'max_depth')\n",
    "cv_results_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the results with a graph and mark the first best result. \n",
    "train_valid_graph(cv_results_dt, 'dt', 'max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Test score with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_dt__max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.01413</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.07728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_dt__max_depth  mean_train_score  std_train_score  mean_test_score  \\\n",
       "3                   4          0.983333          0.01413         0.516667   \n",
       "\n",
       "   std_test_score  \n",
       "3         0.07728  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the results with the highest mean test score. \n",
    "best_results_dt = cv_results_dt[cv_results_dt.mean_test_score == cv_results_dt.mean_test_score.max()]\n",
    "best_results_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_dt__max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.01413</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.07728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_dt__max_depth  mean_train_score  std_train_score  mean_test_score  \\\n",
       "3                   4          0.983333          0.01413         0.516667   \n",
       "\n",
       "   std_test_score  \n",
       "3         0.07728  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among these results, select the result with the lowest tree depth. \n",
    "best_result_dt = best_results_dt[best_results_dt.param_dt__max_depth == best_results_dt.param_dt__max_depth.min()]\n",
    "best_result_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get this tree depth. \n",
    "best_param_dt = best_result_dt.param_dt__max_depth.iloc[0]\n",
    "best_param_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', None), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_dt_optimal = Pipeline([\n",
    "    ('scaler', None),\n",
    "    ('dt', DecisionTreeClassifier(max_depth = best_param_dt, criterion = 'gini', random_state = 0))\n",
    "])\n",
    "\n",
    "# Fit optimal decision tree. \n",
    "pipe_dt_optimal.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the test score. \n",
    "test_score_dt = pipe_dt_optimal.score(X_te, y_te)\n",
    "test_score_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Predictions and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'bad', 'neutral', 'neutral', 'bad', 'bad', 'good', 'good',\n",
       "       'good', 'good', 'good', 'good', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'bad', 'bad', 'good', 'good', 'bad', 'bad', 'bad',\n",
       "       'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'neutral', 'good',\n",
       "       'neutral', 'neutral', 'good', 'good'], dtype='<U7')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the predictions. \n",
    "y_pred_dt = pipe_dt_optimal.predict(X_te)\n",
    "y_pred_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_te</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_dt</th>\n",
       "      <td>good</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>...</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1        2        3    4    5     6     7        8   \\\n",
       "y_te       good  good  neutral  neutral  bad  bad  good  good  neutral   \n",
       "y_pred_dt  good   bad  neutral  neutral  bad  bad  good  good     good   \n",
       "\n",
       "                9   ...       26       27   28   29       30    31       32  \\\n",
       "y_te       neutral  ...  neutral  neutral  bad  bad     good  good  neutral   \n",
       "y_pred_dt     good  ...      bad      bad  bad  bad  neutral  good  neutral   \n",
       "\n",
       "                33    34    35  \n",
       "y_te       neutral   bad   bad  \n",
       "y_pred_dt  neutral  good  good  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the true and predicted target values. \n",
    "pred_comparison = pd.DataFrame([y_te, y_pred_dt], index = ['y_te', 'y_pred_dt']).T\n",
    "pred_comparison.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  good  neutral  bad\n",
       "True class                     \n",
       "good            6        3    3\n",
       "neutral         2        6    4\n",
       "bad             4        0    8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a Scikit-learn confusion matrix. \n",
    "confusion_matrix_dt = scikit_learn_confusion_matrix(y_te, y_pred_dt)\n",
    "confusion_matrix_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The decision tree model performs better than the baseline of 33%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Random forest**\n",
    "\n",
    "In the following cells, we **fine-tune, fit and compute predictions from a random forest model**. In order to fit the model, we must define the 'max_depth' parameter, corresponding to the maximum depth of each decision tree. We could either select the optimal 'max_depth' value obtained in the previous section for a single decision tree, or use the standard value for this parameter, which is None. Both solutions seem reasonable, but we select the second option in order to separate completely the pipelines of the different models, and allow a more objective comparison of their respective accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Grid search with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,\n",
       "        70,  75,  80,  85,  90,  95, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the set of values to explore\n",
    "n_values = np.arange(5, 105, 5)\n",
    "n_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', None), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'rf__n_estimators': array([  5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,\n",
       "        70,  75,  80,  85,  90,  95, 100])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler', None),\n",
    "    ('rf', RandomForestClassifier(max_depth = None, random_state = 0))\n",
    "])\n",
    "\n",
    "# Create cross-validation object. \n",
    "grid_rf = {\n",
    "    'rf__n_estimators': n_values\n",
    "}\n",
    "grid_cv_rf = GridSearchCV(pipe_rf, grid_rf, cv = 5, return_train_score = True, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Fit random forest. \n",
    "grid_cv_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.018162</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.048591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.031180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.067700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.095015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.081650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.074536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.107367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.116070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.140929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.132811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.145774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.128019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>70</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.116070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.113039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>85</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.113039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.127475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.113039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_rf__n_estimators  mean_train_score  std_train_score  mean_test_score  \\\n",
       "0                       5          0.972917         0.018162         0.425000   \n",
       "1                      10          0.997917         0.004167         0.466667   \n",
       "2                      15          1.000000         0.000000         0.525000   \n",
       "3                      20          1.000000         0.000000         0.541667   \n",
       "4                      25          1.000000         0.000000         0.558333   \n",
       "5                      30          1.000000         0.000000         0.541667   \n",
       "6                      35          1.000000         0.000000         0.566667   \n",
       "7                      40          1.000000         0.000000         0.575000   \n",
       "8                      45          1.000000         0.000000         0.591667   \n",
       "9                      50          1.000000         0.000000         0.566667   \n",
       "10                     55          1.000000         0.000000         0.550000   \n",
       "11                     60          1.000000         0.000000         0.600000   \n",
       "12                     65          1.000000         0.000000         0.566667   \n",
       "13                     70          1.000000         0.000000         0.583333   \n",
       "14                     75          1.000000         0.000000         0.591667   \n",
       "15                     80          1.000000         0.000000         0.591667   \n",
       "16                     85          1.000000         0.000000         0.575000   \n",
       "17                     90          1.000000         0.000000         0.575000   \n",
       "18                     95          1.000000         0.000000         0.575000   \n",
       "19                    100          1.000000         0.000000         0.566667   \n",
       "\n",
       "    std_test_score  \n",
       "0         0.048591  \n",
       "1         0.031180  \n",
       "2         0.067700  \n",
       "3         0.095015  \n",
       "4         0.081650  \n",
       "5         0.074536  \n",
       "6         0.107367  \n",
       "7         0.124722  \n",
       "8         0.116070  \n",
       "9         0.140929  \n",
       "10        0.132811  \n",
       "11        0.145774  \n",
       "12        0.128019  \n",
       "13        0.114867  \n",
       "14        0.116070  \n",
       "15        0.113039  \n",
       "16        0.113039  \n",
       "17        0.127475  \n",
       "18        0.113039  \n",
       "19        0.122474  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results with a DataFrame. \n",
    "cv_results_rf = train_valid_dataframe(grid_cv_rf, 'rf', 'n_estimators')\n",
    "cv_results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEXCAYAAABCjVgAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XmcXGWV8PHfqaWreu9Od2fthHRIgLCGJIQARpYWDYuAGy8grig68zKCiIILisuoo/OizigiOKgjCo44uMygImEJCAlZCJCQlXSW7qy9VK+113n/uLcrlU7v6er1fD+f/nTduttzq27dc5/lPo+oKsYYYwyAZ6QTYIwxZvSwoGCMMSbNgoIxxpg0CwrGGGPSLCgYY4xJs6BgjDEmzYLCMBORWSLSJiLeLGz7HhF5eKi3OxSyedwTjYgsE5GtvcyfLSIqIr7hTJcZHywo9EFEPiwir4tIh4gcEJEfi0jJANbfJSJv65xW1T2qWqCqyeykeHQYzuMe6WAoInkicp+I1ItIs4iszJgnIvIvItLg/n1HROR49qeqz6vqyRn7OOqzHuQxLBSRlW7gPigit2bMmy0iz7i/gS297au34xURn4g8KiIhEfmziBRmrPdFEfn08RyDGRoWFHohIp8B/gX4LFAMLAVOAP4mIjkjmTYzdIbgjvoBYBIw3/2feXG7GbgGOAs4E7gS+MRx7m9IiUg58BfgJ0AZMBd4MmORR4BX3HlfBB4TkYoeNtfb8b4bUKAcaOl8X0SqgHcC/z5kB5UFEyaXq6r2180fUAS0Add2eb8AOAR81J2+B3gM+A3QCqwHznLn/RJIAWF3W58DZuP8MHzuMs8C3wBedJf5E86P71c4P5w1wOyM/f8A2OvOWwcsy5h3D/BwD8dzEVALfMZN/37gI/34HALAvwJ7gIPA/UCuO68c+B8gBDQCz+PcaAzbcQPLgRgQd7fzqvv+dOCPbrp2AB/v8jk9Bjzsbu9jwBJgrTt9ELi3n+fJye46RT3MfxG4OWP6JmBVD8v+AviM+3qG+3n9ozs91z0W6fwu+3GOfcj93uqBL/ZyDN8EftnDvJOAKFCY8d7zwCcHerzAncAn3NefBO5zX/8JeEs/PuuPAJtxfmc7O7eVMf9qYIP7fbwJLHffnwT8DNgHNAG/d9//MPBCl20oMNd9/XPgx8ATQDvwNuAKnADZ4p6P93RZ/y3uZxBy538YOMc9p3wZy70H2DDc17V+ndMjnYDR+odzsUlkfpEZ834BPOK+vgfngvRewA/cAdQAfnf+LuBtGet2/mAzL447gBNxciNvANvcE9AH/Cfws4z1b8S5ePpwLvAHgGBGWnoLCgnga246Lwc6gNI+Pofv41xcJwGF7g/4W+68b+EECb/7twyQ0XDcwHPAfUAQWAAcBqq7fGfX4ASxXOAl4APu/AJgaca2XgNu6OHz+SDwOvA9nIvv68B7MuY3A+dmTC8GWnvY1keBP7mvb8C5sP0mY94fMr7L2oz1evqsH3SP7SycC/v8Hvb7NE7QfRHnhuFPwCx33ruAzV2W/yHw7z1sq8fjxbmg/gbIcf//X3f7P+tuW91s+wr3fBHgQpzzd6E7b4m770vd73QGcIo773/d/ZXinKcXuu9/mL6DQjNwgbvNoPvZn+FOn4lzsb/GXX4WTsC63t1PGbDAnfcGcFnGfh7HvQEYbX9WfNSzcqBeVRPdzNvvzu+0TlUfU9U4cC/OybN0APv6maq+qarNwJ+BN1X1KXffvwXO7lxQVR9W1QZVTajq/8O5kz+5+80eIw58TVXjqvoEzp1lj+u6ZcEfBz6tqo2q2opzV3ldxvamASe423xe3TN+JI9bRGbi3LHdqaoRVd0A/BT4QMZiL6nq71U1paph91jmiki5qrap6qqMfZ+pqr/u4RgqgdNxLh7TgVuAX4jIfHd+gTuvUzNQ0EO9wnPAMhHxAG8FvoNzQQLnIvhcD2noyVdVNayqrwKv4gSHno7hQ8CtOBe2Gpwio+7S33kMhXSvt+N9wt32Wvf9R4GvAHeKyD+7dRr39VQ0q6r/654vqqrP4RRxLXNn3wQ8pKp/c7/TOlXdIiLTgMtwcjZN7nk6kM/xD6r6d3ebEVV9VlVfd6dfw/mcLnSXfT/wlKo+4u6nwT33wLmRvBFARCYB7wB6OqdGlAWFntUD5T2UN09z53fa2/lCVVM4xTTTB7Cvgxmvw91MF3ROiMhnRGSzW6EZwrnLzgxQvWnoEuQ6MrfdjQogD1jnVg6GcMqeO8uTv4tzt/+kiOwUkbv6mY5O2Tru6UBnEOu0G+fusdPeo1fhJpyiki0iskZEruznMXQGlG+oasy94DwDvN2d34ZTFNmpCGjrLniq6pvu8gtwLnb/A+wTkZMZXFA4kPG6t+86DDyuqmtUNQJ8FThfRIq7SX/nMbTSvR6P13WXG2RvBu7CyWkudv8uxMlFfLS7DYvIZSKySkQa3XPgco6cAzNxclZdzcQ5F5p6SG9fjjpPRORct9L9sIg04xSD9ZUGcIoq3ykiBcC1wPOqun+QacoqCwo9ewkny/3uzDdFJB/nzmNFxtszM+Z7cO689rlvDVk3tCKyDKdc9lqcYp8SnDuu42rN0ot6nAvGaapa4v4Vq2oBgKq2qupnVHUOTkXh7SJS7a47nMfddV/7gEmZrVtw7oDrMqaPWkdVt6vq9cBknMYFj7nfdV9e62P+Jo6+Qz/Lfa8nz+EUReaoap07/UGcoo8NPaxzvJ/1a1220flacNI6p8tn2dsx9Ot4ReR04HycSvozcHLbilOXdGY3yweA3+HUb01xz4EnOHIO7MUpWupqL8650F2LwXacm57OfUztZpmun+2vcYpTZ6pqMU5Q6ysNuN/lSzjFZR/AqQsalSwo9MAt0vgq8O8islxE/CIyG6dYo5ajv9RFIvJuN1dxG04w6Sx+OAjMGaJkFeLUCxwGfCLyZY69ixsybq7nQeB7IjIZQERmiMg73NdXishct2igBUi6fzC8x30QmO0GZFR1L075+LdEJCgiZ+LkBH7V0w5E5EYRqXCPOeS+3Z/msytxKnM/7za5vACn3Pmv7vz/xAmWM0RkOk59yM972d5zOEVQnc1anwX+Cafsu6f0HO9n/TPgXSKyQET8wN3u/kKqug0nGH3F/SzfhXPR/l0P2+rzeN3z5UfAre7nXQO8xS02uhCnErmrHJwiw8NAQkQu40huDOA/gI+ISLWIeNz9n+Lejf8ZuE9ESt3f8VvddV4FTnOPO4hT19SXQpycR0REluDU/XT6FfA2EbnWPRfKRGRBl8/mczhB8PF+7GtEWFDohap+B/gCzt1JC7Aa526gWlWjGYv+Afg/OC0bPgC8261fAKcy9ktu8csdx5mkv+Kc4NtwikMiHFsMMtTuxCkiWiUiLcBTHCnLn+dOt+HcBd2nqs+684bzuH/r/m8QkfXu6+txKlz34fwAv6Kqf+tlH8uBTSLShlPpep1blIKIbBKR93e3kvs9X41TlNGME0Q/qKpb3EV+glNx+zqwEafS8ye9pOM5nAtPZ1B4AedudmWPaxznZ62qT+Oc5/+LU9E8l6MvdtfhFO80Ad8G3quqhyH9IF1bxrL9Od6PABtVda07/d8439NhnMrZYz4ftyjwU8B/uem4AeeOvXP+y+52v4fzPTyH03wcnN9kHNjiHt9t7jrbcBpePAVsx/ms+/KPwNdEpBX4spuezjTswTkPPoPTUmwDR+eaHnfT9LiqtvdjXyOis6WIGSQRuQentcKNI50WY8zoJiJv4jSlfWqk09ITyykYY8wwEJH34NRRPD3SaemN9Y1iEJFNHMlqZ/qEqvZYDm+M6R8ReRY4FedZmNQIJ6dXVnxkjDEmzYqPjDHGpI254qPy8nKdPXv2SCfDGGPGlHXr1tWrak8dGaaNuaAwe/Zs1q5d2/eCxhhj0kRkd3+Ws+IjY4wxaRYUjDHGpFlQMMYYk2ZBwRhjTJoFBWOMMWkWFIwxxqRlLSiIyEMickhENvYwX0Tk30Rkh4i8JiILs5UWY4wx/ZPNnMLPcboj7sllOF0vzwNuxhkg2xhjzAjK2sNrqrrSHZSmJ1cD/+mOtrRKREpEZNpoHKIuEoH2dti5ExobIRaDeByiUecvEoFw+Oj/HR1H/ofDR6aNMWawbrgBPvGJ7O5jJJ9onsHRA6XUuu8dExRE5Gac3ASzZs3KaqISCecC3toKDQ1QXw/r18Ovfw2vvNK/bYhAIOD8BYOQm+v8BYPgsVocY8wg7dmT/X2MZFDoblzhbrtsVdUHcMZyZfHixUPWrauqcxff3g5NTU4AaGlxEyeweTP86lewdi2UljoReupU8PnA73f+Z178g0EoKoKSEud/fr7zXiAAOTnOn9c7VKk3xpihN5JBoZaMAe85erD7rEgmnYt+a6sTABoanJyBiHORDwahrAzWrYMHH3RyCGVlcNtt8M53OgEkPx8KCo78Dwadi33nhd9yAsaYsWwkg8IfgVtE5FHgXKA52/UJe/fC6687F+9gEIqLj9y5q8Lq1U4wePVVqKiAO+6Aa65xAkckAosXw5Qp2UyhMcaMrKwFBRF5BLgIKBeRWuArgB9AVe8HnsAZ5HoH0IEz6HZWpVJO2X5p6ZH3VOHFF+GnP3UCxpQpcOedcNVVTvBoaHByBBdc4Pw3xpjxLJutj67vY74C/zdb+++LKjz/vBMM3njDqSv4/OedYqKcHCd3cPAgzJoF8+c79QfGGDPeTbhLXSoFzzzjBIOtW2HGDPjSl+CKK5x6BTjS+uiss5z50l2VuDHGjEMTJiikUvDnP8O99zrPG8ycCffcA8uXH50LaGx0pi+4wKlzMMaYiWTCBIWHHoJbbnGCwde+Bm9/+9HBIJl06g8mT4YzznCKkIwxZqKZMEHh+uudYqGTT4by8qPnRSIQCjl1B1VVVlxkjJm4Jkyr+vx8uPLKYx8eC4Wc5w/OOw/mzLGAYIyZ2CZMTqGrVMp5gG3SJDjzTKepqjHGTHQTMijEYk6F8oknwrx51vWEMcZ0mnBBob3dqVS2p5ONMeZYEyooeDxOX0YLFtjTycYY050JFRQqK50/ezrZGGO6N6EujxYMjDGmdxOmSaoxxpi+WVAwxhiTZkHBGGNMmgUFY4wxaRYUjDHGpFlQMMYYk2ZBwRhjTJoFBWOMMWkWFIwxxqRZUDDGGJNmQcEYY0xaVoOCiCwXka0iskNE7upmfqmIPC4ir4nIyyJyejbTY4wxpndZCwoi4gV+BFwGnApcLyKndlnsC8AGVT0T+CDwg2ylxxhjTN+ymVNYAuxQ1Z2qGgMeBa7ussypwAoAVd0CzBYRG/rGGGNGSDaDwgxgb8Z0rftepleBdwOIyBLgBKAyi2kyxhjTi2wGBenmPe0y/W2gVEQ2AP8EvAIkjtmQyM0islZE1h4+fHjoU2qMMQbI7iA7tcDMjOlKYF/mAqraAnwEQEQEqHH/6LLcA8ADAIsXL+4aWIwxxgyRbOYU1gDzRKRKRHKA64A/Zi4gIiXuPICPASvdQGGMMWYEZC2noKoJEbkF+CvgBR5S1U0i8kl3/v3AfOA/RSQJvAHclK30GGOM6VtWRy1W1SeAJ7q8d3/G65eAedlMgzHGmP6zJ5qNMcakWVAwxhiTZkHBGGNMmgUFY4wxaRYUjDHGpFlQMMYYk2ZBwRhjTJoFBWOMMWkWFIwxxqRZUDDGGJNmQcEYY0yaBQVjjDFpFhSMMcakWVAwxhiTZkHBGGNMmgUFY4wxaRYUjDHGpFlQMMYYk2ZBwRhjTJoFBWOMMWkWFIwxxqRZUDDGGJNmQcEYY0xaVoOCiCwXka0iskNE7upmfrGI/ElEXhWRTSLykWymxxhjTO+yFhRExAv8CLgMOBW4XkRO7bLY/wXeUNWzgIuA/yciOdlKkzHGmN5lM6ewBNihqjtVNQY8ClzdZRkFCkVEgAKgEUhkMU3GGGN6kc2gMAPYmzFd676X6YfAfGAf8Dpwq6qmum5IRG4WkbUisvbw4cPZSq8xxkx42QwK0s172mX6HcAGYDqwAPihiBQds5LqA6q6WFUXV1RUDH1KjTHGANkNCrXAzIzpSpwcQaaPAP+tjh1ADXBKFtNkjDGmF9kMCmuAeSJS5VYeXwf8scsye4BqABGZApwM7MximowxxvTCl60Nq2pCRG4B/gp4gYdUdZOIfNKdfz/wdeDnIvI6TnHTnapan600GWOM6V3WggKAqj4BPNHlvfszXu8D3p7NNBhjjOk/e6LZGGNMmgUFY4wxaRYUjDHGpFlQMMYYk2ZBwRhjTJoFBWOMMWkWFIwxxqRZUDDGGJNmQcEYY0xan0FBRG4RkdLhSIwxxpiR1Z+cwlRgjYj8lzu8ZnddYhtjjBkH+gwKqvolYB7wH8CHge0i8k0ROTHLaTPGZGiNtnKg9cBIJ8OMc/2qU1BVBQ64fwmgFHhMRL6TxbQZY1zRRJS1+9ayZt8aaltqRzo5Zhzrs5dUEfkU8CGgHvgp8FlVjYuIB9gOfC67STRmYkumkrx28DVSmmJy/mRePfAqAJVFlSOcMjMe9afr7HLg3aq6O/NNVU2JyJXZSZYxptO2hm3Ud9QzOX8yAOV55bx28DUEYUZR12HPjTk+/Sk+egJo7JwQkUIRORdAVTdnK2HGGKhrqWNn004q8o6MTe7z+CjLLWPDgQ3UtdSNYOrMeNSfoPBjoC1jut19zxiTRc2RZl49+CrleeV0bfTn8/gozyu3wGCGXH+CgrgVzYBTbESWR2wzZqKLJCKs27eOopwifJ7uf26ZgWFf675hTqEZr/oTFHaKyKdExO/+3QrszHbCjJmokqkkrx54FRUl15/b67LpwLDfAoMZGv0JCp8EzgfqgFrgXODmbCbKmIlsa/1WmsJNlARK+rW8z+OjLK/MAoMZEn0WA6nqIeC6YUiLMRNebUstNaEapuRPGdB6nYHhlf2v4MHD1MKpWUqhGe/685xCELgJOA0Idr6vqh/NYrqMmXCawk28fvD1biuW+6OzVdL6A+tZyEILDGZQ+lN89Euc/o/eATwHVAKt2UyUMRNNOB5m/f71FAV6rljuD7/Xz6TgJNYfWM/BtoNDmEIzUfTn7Jurqu8TkatV9Rci8mvgr/3ZuIgsB34AeIGfquq3u8z/LPD+jLTMBypUtRFjhkAsGSOSiBBJRGiLtRFNRLtdrq87c8GZXxQoYnL+ZLwe75ClMZFKsOHABgCCvmAfS/etMzCs27+ORdMWMaVgYEVRQ0lViSQidMQ7aI+30xHvwO/xE/AG8Hl9eMWL1+Pt8b8Zfv0JCnH3f0hETsfp/2h2XyuJiBf4EXApTgX1GhH5o6q+0bmMqn4X+K67/DuBT1tAMAOlqkSTUSKJCOF4mOZoMy2RFlqiLSRSCRBAwevxHnMXntHa+tjtcuy8WDJG0BdkXtk8phZMPa67+s79b6nfQku0hfK88uPaVqZ0jmH/ehZOWzgsgSGZShJOhOmId9ASaaEx3EhztJmkJlEUDx78Hj8pTaXfQ8GNtwhy1HuC4Pf68Xv8+L1+cjw5FAQKmJw/maJAER6x4WCyoT9n9APueApfAv4IFAB392O9JcAOVd0JICKPAlcDb/Sw/PXAI/3YrpmgVJWOeEf6zrMl2kJztJnWaGv6Ai4IPo+PgDdAUaAoK3ebsWSMjYc2sq1+G/PK5jGtcNqgg8Oe5j3sDu0ecMVyf/i9fkqDpazbt47F0xczuWDykG07nozTEe+gI95BKBKiMdxIW6wNRVFV/B4/QV+QkmDJoC/eqkpSk04QSSVpS7TRGG7kzaY3yfHkML1wOlMLplIcLM5agFBV2mJthCIh9rXuoz3ezrSCaVTkV1AcKMbv9WdlvyNJertTcju9e6+q/teANyzyXmC5qn7Mnf4AcK6q3tLNsnk4uYm53eUURORm3Gaws2bNWrR79+6ui5hxTFWp76hna8NW2mLOw/WCkOPNIeANkOPNGVTF7PGKJ+OEIiG8Hi8nlZ3E9MLpA7pINIYbWV27mkm5k447x9GbWDJGU7ipz8CQTCVJpBIk1f2fMR1LxogmonTEO2gMNxJJRBAR527eDQDD+T0kUgnaYm3EkjH8Xj8zCmcMWYCIJWO0RFs41H6I/a37iSVjeMRDnj+PHG+Os99UDBQm5U5ieuF0SoIlFOQUjMh52F8isk5VF/e5XG9Bwd3QSlV96yAS8D7gHV2CwhJV/adulv0/wI2q+s6+trt48WJdu3btQJNjxiBVpSHcwJb6LbRGWynMKezzYa6REE/GCUVDeMTDSZNOYnrRdHK8Ob2u0xHv4O97/06eL29I6hH60hkYTio/iUQqQSwRI5ZyLvSxZIxYMgZ0X2QGR3JgPo+PoC+Y1SA2UJkBwufxMaPIDRCB4n7lFDtzA02RJva17iMUCaGq5HhzKMgp6PFYVTVdXJbSFDneHKYVTksXb/V1Dgy3/gaF/nyzfxORO4Df4PR7BEA/yv5rgZkZ05VAT0/WXIcVHRlXZzDYWr+VlmgLhTmF6R5CRyO/109FXgWJVIKtDVvZ1rCNuWVzqSyq7PbCkEgleOXAK/jENywBASDHm8Ok3EnUNNUcVZnbeQdcmFM4qu9ye+Pz+CgJOg/6JVNJ9rfuZ3fzbrziZXrBdKYVTqMkWHJUgIglYzRHmjnccdjJDaRiePCQ78+nPLd/TYJFhDx/Hnn+PMD5Xve37md3aDciQmmwlGmF0ygNlo76XESm/uQUarp5W1V1Th/r+YBtQDXO09BrgBtUdVOX5YqBGmCmqrYfs6EuLKcwfqkqjeFGtjZsJRQJUZhTmP7BjSWJVIJQJISIUFVSxaziWQR8AcA5xo2HNrK/bT9luWUjnNLxLZlKOi3OklG8HidAFAYK2de6j+ZoM6pKwBsgPyd/yHM+na2u2uPtKE4dy7TCaUzKnZSe31nhnkqlSJE68l+PvE6mnDoVVSVFivK8cmaXzB5UmoYsp6CqVYNJgKomROQWnOarXuAhVd0kIp9059/vLvou4Mn+BAQzPqkqTZEmttRvoTnSTEFOQVYqXodLZ39EiVSCmqYadjbtdIJDySwOtB5gT/OeMX18Y4XX46U4WAw4AeJQ+yHqWusGlBsYLBEh15+bLu5MpBLOdx/ak24N17l/QfCI56jpzvqazPfiKach6GCDQr/T3o+cwge7e19V/zMrKeqD5RTGj85gsK1+G43hRgpyCsjPyR/pZA25ZCpJKBpKt6KpyKuwNvhmwMLxMEF/kMXT+7zZ79ZQ1imck/E6iFMctB4YkaBgxoemcBPbGrbREG4g358/og9YZZvX46Ust8wpFtCUBQQzqvWn+Oio1kJuHcAvs5YiM66FIiEnGHQ0kOfPm1DFKB7x2ANXZtQbTO1KBzBvqBNixr9t9dvY0biD/Jz8Ud2ayJiJrD+9pP4J0o2XPcCpwIAfZjMT257QHrY3bmdy/mS7WzZmFOtPTuFfM14ngN2qWpul9Jhx6FDbITYe2kh5XrkFBGNGuf4EhT3AflWNAIhIrojMVtVdWU2ZGReaI82s37+e0tzSUfUUrDGme/25bfstkMqYTrrvGdOr9lg7a/atoSCnYNQ98m+M6V5/goJPVWOdE+5r+4WbXkUTUdbtW4dPfKOyvyJjTPf6ExQOi8hVnRMicjVQn70kmbGuc9CYeCpOYaBwpJNjjBmA/hTyfhL4lYj80J2uBbp9ytmYlKbYdGgToUhoSAeNMcYMj/48vPYmsFRECnC6xbDxmU2PtjVso661bkI9lGbMeNJn8ZGIfFNESlS1TVVbRaRURL4xHIkzY8vu0G7ebHyTiryKkU6KMWaQ+lOncJmqhjonVLUJuDx7STJDKaUp4sk44XiYtlgb8WS875UG4WDbQTYd2mTPIhgzxvWnTsErIgFVjYLznAIQyG6yTHeSqSQd8Y70EInJVJJ4Mk4sFUsPlxhPxY96reqMmds5OLoHD3NK51BZXDlkA7yEIiF7FsGYcaI/v+CHgRUi8jN3+iPAL7KXJNOdcDzM+gPraYm0OH2sux2PiDh9sXeOptX5Os+f120HbIlUgp2hnexo2sEJxScwq3jWcXVX3fkswmgcftAYM3D9qWj+joi8BrwN537zL8AJ2U6YOaI12sqaujUAx92RnM/jS3fjXNdax67QLmYUzmB26WyKAkUD2lY0EWXtvrXkeHKGbVhJY0x29TevfwDnqeZrcYbO/F3WUmSO0tDRwNp9a8n15Q7pADQe8VAaLEVVOdxxmLrWOiryKzix9ERKgiV9jkrVOc5wIpVIj49rjBn7egwKInIScB1wPdAA/AanSerFw5S2Ca+2pZbXD75OcaA4PcbvUBOR9EW9NdrKqtpVFAeLOansJMpyy7oNDilN8frB12mJttg4w8aMM73lFLYAzwPvVNUdACLy6WFJ1QSnquxo3MG2hm2U55UPW+VtYaCQwkChU09Qt4Z8fz4nlZ1ERf6R4SNVla31W9nftt+eRTBmHOrtavMenJzCMyLyF+BR0m1YTLYkU0neOPwGe5v3jtjYA/k5+eTn5BNJRHjlwCsEfUHmlc1jasFUaptrqQnVMDnPBskxZjzqMSio6uPA4yKSD1wDfBqYIiI/Bh5X1SeHKY0TRiwZY8P+DTRGGpmcP7nPcv1sC/qCBH1BYskYGw9uZPPhzcSSMSryKkY8bcaY7OjzNlRV21X1V6p6JVAJbADuynrKJpj2WDur9q6iJdYy6i66Od4cKvIrKAoUUZ5XbgPPjwBV7XXamKEyoLIJVW1U1Z+o6iX9WV5ElovIVhHZISLdBhIRuUhENojIJhF5biDpGS9CkRAv1r5ISlOUBktHOjk98nl89nDaCPjJup9w76p704FAVbl31b38ZN1PRjhlZjzKWoG1iHiBHwGX4YzrfL2InNplmRLgPuAqVT0NeF+20jNaHWw7yEt7XyLPl2fdTJtjqCptsTYe2fhIOjDcu+peHtn4CG2xNssxmCGXzdu+JcAOVd0JICKPAlcDb2QscwPw36q6B0BVD2UxPaOKqrI7tJtNhzdRlluG3+sf6SSZUUhEuH3p7agqj2x8hEc2PgLA9adfz+1Lbx9VxYxmfMhm05YZwN6M6Vr3vUwnAaUi8qyIrBORbsdpEJHPAW7jAAAgAElEQVSbRWStiKw9fPhwlpI7fFKaYkv9FjYd3kRFXoUFBNOnZCp51LQFBJMt2QwK3Z2xXfO6PmARcAXwDuBu96G5o1dSfUBVF6vq4oqKsd0tczwZ59UDr7IrtIsp+VOs0tb0KqUpvv3Ct/nt5qOHRX/vb99LU7hphFJlxrNsFh/VAjMzpiuBfd0sU6+q7UC7iKwEzgK2ZTFdIyaSiLBu/zraY+3H3YeR6b8DbQd4uuZpXjnwCstmLePyeZePiQrzlKb45vPf5Pdbfw/Adaddx6eWfIqb/+dmNh7eyJWPXMk9F97DpSdeOsIp7V4oEqKmqYadoZ3UNNWwu3k3sWSs7xV7IAinTT6Nt1W9jVPKT7GcUpZItiqqRMSHc3GvBuqANcANqropY5n5wA9xcgk5wMvAdaq6saftLl68WNeuXZuVNGfb+v3raehoYFLupJFOyrhX11LH07ueZkXNCjYeck6n0mApTZEmZhTO4CMLPsIV864YtUV3KU3xz8//M3/Y+gcWTFnAKeWn8JnzPoOIoKrc/czdrNm3hoZwA9VV1Xzu/M9Rljf8XY6oKk2RJnY27aQmVOP8b6qhJlRDQ7ghvVyuL5cTSk4gz5c36H1Fk1G21G8hqUmmF0ynek411VXVnFZx2oQIEOF4mKA/yOLpiwe1voisU9U+V85aUHATcTnwfcALPKSq/ywinwRQ1fvdZT6L0x13Cvipqn6/t22O1aAQioR4ae9LlkPIotqWWp7a+RRP1zzNG/VOe4ZTyk+huqqaS2ZfwqziWbyw5wUeXP8gb9S/wdSCqXz4rA9z1clXjapuv5OpJN94/hv8aduf+PjCj3PzwpsBjrrwqSpJTfLwaw/zk3U/Ic+fxx3n38HyE5dn7QLZGG5ke+N25+4/Iwg0R5vTy+T785lTOoeqkirnf2kVc0rmMKVgypA8nR+KhHhu93OsqFnBy3Uvk0glmJI/heqqaqrnVHPG5DPG7SBP4yIoZMNYDAqqyura1USTUQpyCkY6OePK7tBuVtSs4Kmap9jW4JQ6nlZxmhMIqi6hsqjymHVUlRdrX+TB9Q+y8dBGJudP5kNnfYhrTr4max0P9lcyleSrz32VJ3Y8wScWfYKPL/x4n+vUNNXwtZVf4/VDr7Ns1jI+/5bPD9nNx/7W/ayoWcHTNU/z2qHX0u8X5hQyp3TOUQFgTumcYX3wsiXawsrdK1lRs4JVtauIp+JMzp/MJbMvobqqmjOnnDmu6uwsKPRgLAaF+o56Xq572TqQGyI7m3ayomYFK2pWsKNxBwBnTj6TS6qci8G0wmn92o6qsrpuNQ+uf5BXD75KeV45HzrrQ7zrlHeNyPgQiVSCe569h7+8+Rf+YfE/cNPZN/V73WQqyaObHuW+Nffh9/r59NJPc9VJVw3qAl3bUpv+fN847OS4Tio7iUtmX8JZU86iqrSqxx50R0pbrI3n9zzPip0reLH2RWLJGGW5ZelzYsHUBWOiHqk3FhR6MNaCQkpT/H3P3xGEXH/uSCdnzEmkEtS21LKzaSdb6rfwzK5nqAnVIAgLpi6guqqai2dfzJSCwQdcVWXd/nU8sP4B1u9fT1luGR848wO8Z/57hu07S6QS3P3M3fxt59+45Zxb+PCCDw9qO3ub9/L1lV9n/YH1nDvjXL607Ev9CpJ7mvekA8GW+i0AnFp+avqiOrN4Zh9bGD3aY+38fe/fWVGzghf2vEA0GaU0WMpFsy9iasHUEU3b5PzJzCmdw+zi2QMeH8WCQg/GWlDY37qfDQc2WF1CH2LJGHua9xzVWmVnaCd7mveQSCUAZ2CghVMXUj3HCQTleeVDno51+9fxH+v/g5f3vUxJsIQbz7iRa0+7ljz/4CtI+5JIJfjC01/g6ZqnufXcW/nAmR84ru2lNMXvNv+Of1v9b4gIn1ryKd49/93HlLXXNNWkA8H2xu0AnDH5jHTR2/TC6ceVjtEgHA/zYu2LrKhZwfO7nyecCI90ktKmFkxlTolT75Kugymp6rFnAwsKPRhLQSGZSrJy90oC3sCIl1WPFpFEhD3Ne45urRKqYW/zXpLqPKAlCJVFlelKys7/s0tmD9ud+4YDG/jp+p+yqm4VxYFi3n/G+7n2tGuHvE4onozzhae/wDO7nuH2pbdzwxk3DNm297Xu4xvPf4OX615m4bSF3L3sbqLJqBMIdq5gZ2gnAGdNOSsdCEb6TjqbUpoipakR3f/+1v1Hnfc7m3ayK7SLaDKaXq4ir+KYc7+qtIqAN2BBoTtjKSjsbd6brsicyCKJCL/f8nse2/wYe5r3pH+YXvEys3jmUXdJc0rnMKt41qgZ8/n1g6/z01d+yt/3/p3CnEIunXMp1XOqWTRt0XGXUceSMe5acRcrd6/kjvPu4LrTrxuiVB+hqvxh6x/43qrvEU6ESWkKQTh72tnporeJfn6OtGQqyf62/enccWaz3sycTWmwlA+c+QF+cNkPBrUfCwojLJ6M89zu5yjwF4zatvDZFklEeOyNx/jla7+kIdzAgikLOGfGOcwpmZO++I+Vz+aNw2/wy9d+yfN7nieSiFAcKObi2RdTXVXNOTPOGXCAiCai3PnUnbyw9wXuvOBO3ndqdvuCPNh2kEc2PkJlUSUXzb4oK0VvZmilNMXBtoPp4tTtjds5f+b5fGHZFwa1PQsKI+zNxjfZ0bhj1Pz4EqkEe5v3MrN4ZtZbYXTEO3jsjcd4+PWHaQw3cs70c/jYwo+xaNqirO53OEQSEV7a+5JTRr3nedrj7RQFirjwhAuprqpmyYwlfT7zEE1E+ezfPsuLtS/yhbd8gXfPf/cwpd6MZcNVpzC222iNUpFEhB2NOygJloxoOhKpBGv3rWVFzQqe2fUMoUgo3QqjuqqaxdMXD2mAaI+189s3fsvDrz9MKBJi6YylfGzhx1gwdcGQ7WOkBX1BLq66mIurLiaaiLKqbhUrdjrt+P+07U8U5BTw1llvpXpONUtnLD2mLimSiHDHk3ewum41X1r2Ja455ZoROhJjumdBIQt2hXYhIiPSLjqejLO6bjUralbw3O7naIm2kOfPY9msZZw99WzWH1jPX3b8hce3PE5xoNi5w51TzZLpSwZdlNMWa+PRjY/yyMZHaI42c8HMC/jY2R/jjClnDPHRjS4BX4ALT7iQC0+4kFgyxst1L6c/9yd2PEG+P59ls5ZRXVXNeTPPA+D2v97Omn1r+PKFX+adJ71zhI/AmGNZ8dEQa4+1s3L3SsrzyoftcftoIsrqutU8tfMpVu5ZSVusjXx/Pm894a28bc7bjrljjSQirKpdxYqaFazcvZL2eDuFOYXpIpBzK8/tV7cPLdGWdDBojbWybNYyPr7w45xacWqf645niVSCNXVr0jm05mgzub5cKvIqqG2t5SsXfoUr5l0x0sk0Y4w1Se3BaA8Krx14jUPthyjNze6wmt2VbRfmFKaLhvpTtg1OC5jVtUdyFq2x1nRAqa6qZmnl0mNaAoUiIR7Z+AiPbnyU9ng7F8++mJvOvolTyk/J1uGOWYlUgvX717OiZgVr6tZw86KbWT53+Ugny4xBFhR6MJqDQku0hRf2vMDkvMlZ6QIgHA8f9aRmOBE+qhXM4umLj6s1TzwZZ80+5w732V3P0hxtJs+fx1tmvSXdG+XvNv+O32z6DR3xDqqrqrnp7Js4qeyYITCMMUPMgkIPRnNQWLtvLa3RVooCRUO2zfZYOy/sfYEVNSv4+56/px/Zv3j2xUPWXr47mZXUz+56lqaIM6CLIFx64qV8dMFHmTtp7pDv1xjTPWt9NMY0hZs41HbouPrg6dQWa0v3/vhS7Uvpzr2uOvkqqquqOXvq2Vnv/dHn8bG0cilLK5dy5wV3suHABl47+BoXz76YqtKqrO7bGDNyLCgMAVVlc/3m4+oCoadugN8z/z1UVzn9xI9UN8A+j4/F0xcP+g7FGDN2WFAYAvUd9TRHmgfcXUAoEuLZXc/ydM3TrK5bTVKTTC2YyrWnXUt1VTWnTz593A4YYowZnSwoHKeUpth8eHO/6xEaw408u+tZnqp5inX71pHUJDMKZ/D+M95P9ZxqTi0/dVT1U2+MmVgsKByng20HaY+395lLqG2p5ZvPf5O1+9eS0hSzimbxwbM+SHVVNSeXnWyBwBgzKlhQOA6JVILNhzf32Z1FKBLiU3/5FKFIiI8u+CjVVdXMnTTXAoExZtSxoHAc6lrqiCVjFAeLe1wmmohyx5N3cKDtAPddft+46gfIGDP+WFAYpFgyxrbGbb0+uZzSFF9d+VU2HNzANy/5pgUEY8yoZ01bBml3aDepVKrXB8d+vPbHPPnmk/zTkn/i7Se+fRhTZ4wxg2NBYRAiiQhvNr1JabDnXMJ/b/5vfrbhZ7z7lHfzwTM/OIypM8aYwctqUBCR5SKyVUR2iMhd3cy/SESaRWSD+/flbKZnqOxs2olXvD0+TPbi3hf5l7//C+fPPJ/PXfA5q1A2xowZWatTEBEv8CPgUqAWWCMif1TVN7os+ryqXpmtdAy19lg7u0O7exxRbWvDVu5acRdzJ83lW5d8a0TGVDDGmMHKZk5hCbBDVXeqagx4FLg6i/sbFtsbt5Pjzen2SeMDbQe47S+3UZhTyPff8X3yc/JHIIXGGDN42QwKM4C9GdO17ntdnScir4rIn0XktO42JCI3i8haEVl7+PDhbKS1X5rCTexr2Udx4NgmqG2xNm776210xDv4wfIfUJFfMQIpNMaY45PNso3uCtK79tO9HjhBVdtE5HLg98C8Y1ZSfQB4AJyus4c6oX1pjbayK7SL2pZaCnIKjqkjSKQS3PnUndQ01fCD5T+wLqWNMWNWNoNCLTAzY7oS2Je5gKq2ZLx+QkTuE5FyVa3PYrr6rTnSzM6mnRxoO0CON4eKvIpjAoKq8q0XvsXqutXc/da7WVq5dIRSa4wxxy+bQWENME9EqoA64DrghswFRGQqcFBVVUSW4BRnNWQxTX1SVUKREDsad3C443B6bN2eWhA9tOEh/rD1D9x09k1cffKYrzIxxkxwWQsKqpoQkVuAvwJe4CFV3SQin3Tn3w+8F/gHEUkAYeA6HaGh4FSVxnAj2xu20xhpJN+fz5T83gfM+fOOP/PjtT/msrmX8clFnxymlBpjTPZktb2kqj4BPNHlvfszXv8Q+GE209CXlKao76hnW8M2WqOt/QoGAOv2r+Nrz32NRdMWcfdb77ZnEYwx48KEbUSfTCU51H6IbQ3b6Ih3UJhT2O9BcmqaarjjyTuYUTSD7176XXK8OVlOrTETj6qS0hRJTTr/U0m8Hi9BX3CkkzauTbigkEglONB2gO0N24kkIhQFigY0YlpDRwO3/uVW/F4/P3jHD/o9uM5IU1WaIk0kU0n8Xj8Bb4CALzChRnaLJ+MA+L3+EU7JxJNIJYglY8ST8fSFXlGnPaKbyZaMBouKIgh+rx+/x4/f6yfXl0s0GeVQ+yFEhHx/Pnn+vJE5oHFsQgWFxo5G1h9YTzwZpyRYMuALeiQR4dNPfpqGcAMPvPMBZhR199jF6NMWa6Mj3sEJxSdQnl9OKBIiFA6lg4SI4MFDwBcg6AuOu6ew48k4TZEmAt4A8VScgpwCu9vMgngy7lz4U3ESqYRz0XcFvAEKA4WU55WT480hx5uD3+tPdxfT0//uRBIRGjsa2duy96gAkevLtWLcITC+fv19CEVDqOqAx1IGp7jpi09/kc2HN/PdS7/LaRXdPmc3qsSSMUKREMXBYs6fen563IfO41dVwokw4XiY1mgrTZEmmiJNRBNRRARByPHmEPQFx2QRWefxB7wBzphyBlMLptIWa2N17WoACwyDEEvG0nf8iVTiqLv8oC9IYU4hBYECigJF6dxowBvo8QI/GEFfkOlF05leND0dIOpa66jvcFqy5/nzyPPnWYAYpAkVFODoLGp/tcXa+NLTX+KFvS9wx3l3cNHsi4Y+YUMopSmawk14PB7OmnoWUwumdltMJCLpH1BZXhmzmQ04AwOFE2HaY+2EIiEaw400R5qdC4CC1+Mlx5tDwBsYlUUx3QWDztxPSbCEcyvPZXXtalSVXH/uCKd2bIgkIjRHmsnPyacoUJS++Ad9wREtiswMENFElMZwI7UttRzucHo+yPPnke/PtwAxABMuKAzU3ua93P7k7exp3sOdF9zJ+05930gnqVet0VbCiTBVpVXMKZ0zqDv8gM/5kZcES9JFZIlUgnA8TDgRpi3WRnOkmZZoC6FoKL2eIPg9fgK+QI/9Q2VTLBmjOdpMjifnmGCQqSRYwtLKpayuW42iVi7di0QqQVO4iaA/yJLKJZTllo3aC2zAF2Ba4TSmFU4jmojSFG6irrXuSIDw5FEYLUSSMqibw5GWr05w29y8udflgsEglZWV+P2Du2GzoNCLl+te5q4VdyEIP7r8Ryyevnikk9SjaCJKKBKiLK+MRdMXURgoHNLt+zw+CgOFFAaObqWVTCWJJqNEEhHC8TAt0Raao82EIiGSmnQWyshdZKPOIjMYnD759B6DQabiYLETGNyiJAsMR1NVmqPNxFNxTik/hZnFM4e0CCjbAr4AUwunMrVwKrFkjKZwE/v37mdSySSKSorweDx4xDMswSGlKVKaOuo9j3gGfNOU0hQe8fTa0aaq0tDQQG1tLVVVVYNKrwWFbqgqv9n0G7636nucUHIC9779XiqLKo9rmylN0RJtIZlKkuvPJegLDsmddDKVpCnShN/jZ9H0RUzOnzysd3Jej5c8j1MERS7McPs8VFViyVg6YHTmLkKRENFkNL2+3zP4llCDCQaZigJFTlFSnVOUZL3aOjriHbREW5hZNJN5ZfPGfBFbjjeHKQVTaKSRGVNmoKrEU3HiqTidz8oO5iLdE0VJpVLpinafx0fAF8ArXkSEZCpJLBlz6mSGeN8iQllZGcfTcagFhS7iyTjfefE7PL7lcZbNWsbXL/46BTkFx7W95mgzijKreBZBX5DGcCON4UaSmkwXuXSWzQ7kgt4caSaajDJ30lxml8weVeX7IpIuhura7DeejKcruJujzYTCoaNyFp0V3AGvUwzV9TM53mCQqShQxNIZTlESMUZ1YOiIdxBOhMn352elkjyRStAYbqQwUMj5M8/vdfzxsaozt+Pz+ghqMN08Nl1xjnPuDjQXkZkbEHHOX5/Xlw4EmTxeD36vn5Sm0k11O/fd3fIDdbzrW1DI0BRu4nNPfY5XDrzCRxZ8hH9Y/A+DjuDtsXba4+0EfUFOKT+FqQVTCfgCAMwpnYOq0hHvoCPeQVOkifqOehrCDUfaZ3v85Ppzu60T6Kz0m1wwmfnl80f1haw7fq/T7rwoUMSUAufpcVUlmowSjofpiHcQijhNZuvDR/pG9IqXpCaHJBhkKgwUsrRyKatqV6ExPa6bgGzo7IIl6Asyb9I86lrr0k0x83zH39JGVWmMNCIIZ0w5g+mF0yfE8ysi4jR9xSnaVFWSmiSRTBBLxXrNRfSWG+hvMZtHPOnmuclUMh0gkinn5sjr8Y5I3YcFBde2hm185snP0Bhu5BsXf4Plc5cPeBudRUSxZIzSYCnzK+ZTllfWY8uf/Jx88nPyqciv4KSyk0imknTEO2iPt9MYbqS+vd7JZajiEQ9BX5BwPEzAFxj1lX4DJeI0aQz6gpTmlqYruJOp5JFms7FWAt4AUwqmDHm9REFOQbqOoS3WNmoCQzwZpyHcwAklJ3By2cn4vX6qSqsIx8PO+B5t+6hvr0dRgr4g+f78AZX9t8XaaI+3M7tkNieWnpi+cZmIRASf+JwLvAa6zUV08oiHHF8OPk/3uYHuhEIhfv3rX/OP//iPx8zzepxgEvAFSKaSxFPOMx+qyvuueR8P/edDFBcfO45LNlhQAJ6ueZovP/tligJFPPjOBzm14tQBrZ9ZRDSzaCYzi2cO6klnr8ebrsydWjAVKpxtt8fbaYu20RBuYGbxTGYVzxp3D5j1xOvxUpBTQEFOQdYHLhptgaE12ko0GWXhtIVMK5x21Lxcfy65/lymF00nnowTioQ40HaAA20HSKQS+D1+CnIKeixSjCaiNEebKQ2Wcva0s8fMk/nDpadcROcN2mAq3UOhEPfdd98xQSGZTOL1HtleOkB4AyQ1yR//9EdiqRhJTQ5LDm5iXFl6kNIU//HKf/CTdT/h9Mmn86+X/muPYy93pyPeQVu8jYAnwMllJzOtcNqQ32n5vX5KvCWUBEuoLD6+ym7Tt/ycfM6tPJeX616mNdo65K24+iOlKRo6GigKFnHOjHP6LB70e/1U5FdQkV/BqRWn0hJt4XDHYepa6miKOM+rFPidZwqSqSShaAiveDl76tlMKZgybnKbA3HbbbBhw0DWEPq6XC5YAN//fs/z77rrLt58800WLFiA3++noKCAadOmsWHDBt544w2uueYa9u7dSyQS4dZbb+Xmm2/GJz7mzpnLmjVraG5t5sorrmTZW5bx4osvMmPGDP7whz+Qmzu0DQEmbFAIx8Pc89w9rKhZweVzL+eLy77Yrwt6ZhFRcbCYRdMWUZZbNqaa65nedQaG1bWraYm2DOtddCQRoTnazImlJzJ30twBn1dej5fS3FJKc0uZN2kebbG29ANdh9oPAYzKhgkTwbe//W02btzIhg0bePbZZ7niiivYuHFjuunoQw89xKRJkwiHw5xzzjm85z3voaysDHCLtjw+dmzfwaOPPMqDDz7Itddey+9+9ztuvPHGIU3nhAwKB9oOcPuTt7O9YTu3nnsrN55xY7/ulpqjzUQTUSqLKplVPCvdbYQZf/L8eZxbeS5r6tYMW2Do7IZlyYwlA8qx9kRE0sWRJ5ScQDgetof1XL3d0Q+XJUuWHPUswb/927/x+OOPA7B37162b9+eDgqdqqqqWLBgAQCLFi1i165dQ56uCRcUNh7ayNdWfo1YMsb33vE93jLrLf1ary3Whk98nDf7vDHfbtv0T54/jyUzlvBy3cs0R5qzdhOQTCVpCDdQkV/B6ZNPz1qfTHbeji75+UeKBZ999lmeeuopXnrpJfLy8rjooouIRCLHrBMIHCnN8Hq9hMPhIU/X+G93luG3m37LZ5/6LAU5Bfz86p/3OyBEEhFiqRiLpi+yH9YEk+vPZcmMJfg8PkKRUN8rDFA4Hqa+o56Ty09m4bSF1knfOFZYWEhra2u385qbmyktLSUvL48tW7awatWqYU7dERMmp/CLDb/grhV3sXDaQv710n/td3FAZ8ui8yrPG3PPA5ihkevPZUnlEtbUreFg+0GC3mC698/BVtJ2jm/h8/g4f9b5lARLhjjVZrQpKyvjggsu4PTTTyc3N5cpU46M8Lh8+XLuv/9+zjzzTE4++WSWLl06YumUERoSedAWL16sa9euHfB6bbE2vr7y61xywiWU5/evvDaZSnK44zCLpi1iauHUAe/TjC/RRJT6jnpaoi00RZpojbaiaLqZYueDSH0Fi0QqQX1HPZVFlcyvmD8muyUfizZv3sz8+fNHOhnDortjFZF1qtpnB24TJqdQkFPAJxZ9gp2NO/u1vKpSH653nka2gGBwOlmbUTTjqP6dIolI+uG6UMTprqMx0pgevEhEyPEc6bKjPd5OOB7mrKlnMaNwxoRsDmpGtwkTFAaqvqOeWcWzmFM6Z6STYkYpEUk/REYu6aewU5oikogQSUToiDlddjRHm2kIN1CQU8AFsy4YkecfjOkPCwrdaIo0UZZXxvzy+XYnZwbMI5704EWTcielHzrs7DBtIvQrZMaurJ6dIrJcRLaKyA4RuauX5c4RkaSIvDeb6emP1mgrOZ4czpp6lj2QZobUUHaRbEy2ZO0MFREv8CPgMuBU4HoROaZTIXe5fwH+mq209FckESGucRZNX2SVf8aYCSmbty1LgB2qulNVY8CjwNXdLPdPwO+AQ1lMS586m56eM73vvmaMMWa8ymZQmAHszZiudd9LE5EZwLuA+7OYjj51PlG6cOpCay9ujMmKzl5SB+P73/8+HR0dQ5yi7mUzKHRXQ9v1oYjvA3eqdg7m28OGRG4WkbUisvZ4hpnrjqpyuOMw8yvmW9NTY0zWjJWgkM3WR7XAzIzpSmBfl2UWA4+6LXzKgctFJKGqv89cSFUfAB4A5+G1oUxkfUc9s0tmU1UyuEGujTFjz21/uY0NBwbUd3afFkxdwPeX99zTXmbX2ZdeeimTJ0/mv/7rv4hGo7zrXe/iq1/9Ku3t7Vx77bXU1taSTCa5++67OXjwIPv27ePiiy+mvLycZ555ZkjT3VU2g8IaYJ6IVAF1wHXADZkLqGr6SiwiPwf+p2tAyKbGcCPl+eWcUn6KNT01xmRVZtfZTz75JI899hgvv/wyqspVV13FypUrOXz4MNOnT+d///d/AadPpOLiYu69916eeeYZysuPv/fcvmQtKKhqQkRuwWlV5AUeUtVNIvJJd/6I1iO0RlsJ+oKcOeVMa3pqzATT2x39cHjyySd58sknOfvsswFoa2tj+/btLFu2jDvuuIM777yTK6+8kmXLlg172rL68JqqPgE80eW9boOBqn44m2nJ1Nn0dMn0Jdb01Bgz7FSVz3/+83ziE584Zt66det44okn+PznP8/b3/52vvzlLw9r2ibckzTx1JGmpzbYiDFmuGR2nf2Od7yDhx56iLa2NgDq6uo4dOgQ+/btIy8vjxtvvJE77riD9evXH7Nutk24bi464h1cMPMCa3pqjBlWmV1nX3bZZdxwww2cd955ABQUFPDwww+zY8cOPvvZz+LxePD7/fz4xz8G4Oabb+ayyy5j2rRpWa9onjBdZwPUtdQRS8aoKrWWRsZMNNZ1tnWdfYzOXiyNMcZ0b8LVKRhjjOmZBQVjzIQx1orLB+N4j9GCgjFmQggGgzQ0NIzrwKCqNDQ0EAwGB72NCVWnYIyZuCorK6mtrWWo+08bbYLBIJWVlYNe34KCMWZC8Pv9VFVZy8O+WPGRMftiWt4AAAlRSURBVMaYNAsKxhhj0iwoGGOMSRtzTzSLyGFg9yBXLwfqj2P3E3390ZAGW9/Wt/UH5wRVrehzKVWdMH/AWlvfPkNb39afqOv358+Kj4wxxqRZUDDGGJM20YLCA7b+cRvpNNj6tr6tn0VjrqLZGGNM9ky0nIIxxpheWFAwxhiTNmGCgojsEpHXRWSDiPQ5dJuIPCQih0RkY8Z7k0TkbyKy3f1fOsD17xGROjcNG0Tk8l7Wnykiz4jIZhHZJCK3DiQNvazfrzSISFBEXhaRV931vzrA/fe0fr8/A3d5r4i8IiL/M5D997L+QL6DY86ZAZ4D3a0/kP2XiMhjIrLF/R7PG+D+u1u/v9//yRnLbBCRFhG5bQDff0/rD+T4P+2eOxtF5BH3nBrI8Xe3/kD2f6u77iYRuc19byD77279HvcvA7zmiMjnRWSHiGwV+f/tnX3MVmUdxz/fHhABUXwfQQUx1psZskTThiWtwhq+bCouNtl6WVusUXMNZ3PlP0VZq83GSpw0M5mWpTVzGOLL2qIJAqL0phCSCFrhS04T+PXH73pu7wfPubl+DzAYz++znd3XOc/5nu91nXOdc53ruu/nd+kTbfkIc7B/83q4LMBm4KTA/jOAacCGrm3fARaW9EJgUVD/DeCqSv9xwLSSHgP8FXhvbR566KvyAAg4pqSHA6uAswP+bfrqc1C0XwV+Dvw2eg1a9JFr8KY6E6wDTfqI/0+Bz5X0UcDYoH+TPnT+i7YPeBZ4R/T8N+hr6994YBMwsqzfDswL1L82fa3/acAGYBQeOPT3wJSAf5u+1Z/AMwe/l9cBI4BJwJNAX+S6ti1DpqcQxcweAv691+YL8RuN8nlRUB/x32Zma0r6JWAjXtGr8tBDX+tvZvZyWR1eFgv4t+mrkTQB+BSwpGtz9TVo0e8v1f77g6Rj8YfETQBm9j8z21nr30M/GGYCT5rZP2r9e+gjDANGShqGP1yfCfo36Wt5D/BHM3vFzHYBDwIXB/zb9K0EnzkXAsvM7DUz2wT8HZheW7heDKVGwYDlklZL+sIgj3GqmW0Df+gCpwziGPMlrS9dxZ5DH/1Imgicgb9th/Owl746D/Khl7XADuA+Mwv5t+ir/YEfAF8D9nRti5S/SR/xb6ozEf+2Olfj/07gOeBm+fDXEkmjA/5t+kj5+5kD3FbSg7kHuvVV/mb2T+B6YAuwDXjBzJbX+vfQV/njb/kzJJ0oaRRwAfC2QPnb9LX+/bT5jQee7tpvK4GXvl4MpUbhXDObBswCviRpxiHIw2JgMjAVr6jf25dA0jHAL4EFZvZi1LBBX50HM9ttZlOBCcB0SadFvFv0Vf6SPg3sMLPVEc8KfeQa7G+dadLX+g/DhxIWm9kZwH/x4YNa2vShOijpKGA2cEfAu5e+9vofj78NTwLeCoyWNDfg26av8jezjcAi4D7gXnyoZletfw99+BnQgppsB3msAQyZRsHMnimfO4BfMbiu1nZJ4wDK545gHraXB+Ue4MZ95UHScPyBfquZ3RnNQ5M+moei2Qk8AHwy4t+kD/ifC8yWtBlYBpwv6WcB/0Z9pPwtdaa6/E36gP9WYGtX7+oX+EO+1r9RP4jrPwtYY2bby3r0+g/QB/w/Bmwys+fM7HXgTuCcgH+jPnj9bzKzaWY2Ax/W+Vuk/E36QZz/Nr+tvNHzAH/xigyPtTIkGgVJoyWN6U8DH8e7d1HuBq4s6SuBu4L5GNe1enGvPEgSPh680cy+H81Dm742D5JOljS2pEfiN9mfA/6N+lp/M7vazCaY2UR8+OF+M5tb69+mD5S/rc7Ulr9RHyj/s8DTkt5VNs0EngiUv1EfqYOFKxg49BO9BwboA/5bgLMljSp1eSb+vVitf6M+eA+eUj7fDlxSylFd/ib9IM5/m9/dwBxJIyRNwr/E/tM+jlWHHYBvqw/3BR9fXVeWx4FrKjS34d271/FW+bPAicAK/I1hBXBCUH8L8BiwvlzUcT30H8a7g+uBtWW5oDYPPfRVeQBOBx4t+20Ari3ba/3b9NXnoOtYH+GNXw9VX4MWfW35G+tMoPxt+kgdmAo8Uvb9NXB8sA426SP+o4B/Acd1bYv4N+kj/t/EX0Q2FN2IoH+TPuL/MN4QrwNmDqL8TfpWf4LPHOAa/FdHfwFm7es+qF0yzEWSJEnSYUgMHyVJkiR1ZKOQJEmSdMhGIUmSJOmQjUKSJEnSIRuFJEmSpEM2CkmSJEmHbBSSpAJJUzUwzPFsSZGwE72OvaDEx0mSQ07+n0KSVCBpHvBBM5t/EI69uRz7+YCmz8x2H+i8JEn2FJIjCkkT5RPK3Cif3GR5CbPRtO9kSfeWKKYPS3p32X6pfHKUdZIeKkHdrgMul0+McrmkeZJuKPsvlbRYPqnRU5LOKxEwN0pa2uW3WNIjGjjp0JfxgG0rJa0s266QT86zQdKiLv3Lkq6TtAr4kKRvS3pCHnHz+oNzRpMhx4H61+hccjkcFmAiHo1yalm/HZjbsu8KYEpJn4XHRwIPQzC+pMeWz3nADV3azjqwFA+6Jzwy54vA+/GXrtVdeTmhfPbhAQJPL+ubKZPx4A3EFuBkPNLp/cBF5W8GXNZ/LDy8gbrzmUsu+7tkTyE5EtlkZmtLejXeUAxAHlL8HOAO+ZwPP8ZnqwP4A7BU0ufxB3gNvzEzwxuU7Wb2mHkkzMe7/C+TtAaPCfU+fPasvTkTeMA8uucu4FZ8shyA3XjUW/CG51VgiaRLgFcq85kkPRl2qDOQJAeB17rSu4Gm4aO3ADvN53sYgJl9UdJZ+KxtayW9aZ8ennv28t8DDCuRLK8CzjSz/5RhpaMbjtMUJ7+fV618j2BmuyRNx6N/zgHmA+dX5DNJepI9hWRIYj7h0CZJl4KHGpf0gZKebGarzOxa4Hk8bv1L+FzXg+VYfKKbFySdis8z0E/3sVcB50k6SVIfHnr6wb0PVno6x5nZPcACPCJqkuw32VNIhjKfARZL+jo+h/QyPMzxdyVNwd/aV5RtW4CFZajpW1EjM1sn6VF8OOkpfIiqn58Av5O0zcw+KulqYGXxv8fMmmL2jwHuknR02e8r0TwlSRP5k9QkSZKkQw4fJUmSJB1y+Cg54pH0I3zO5m5+aGY3H4r8JMnhTA4fJUmSJB1y+ChJkiTpkI1CkiRJ0iEbhSRJkqRDNgpJkiRJh/8DWVCRFNjdIdoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the results with a graph and mark the first best result. \n",
    "train_valid_graph(cv_results_rf, 'rf', 'n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Test score with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.145774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_rf__n_estimators  mean_train_score  std_train_score  mean_test_score  \\\n",
       "11                     60               1.0              0.0              0.6   \n",
       "\n",
       "    std_test_score  \n",
       "11        0.145774  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the results with the highest mean test score. \n",
    "best_results_rf = cv_results_rf[cv_results_rf.mean_test_score == cv_results_rf.mean_test_score.max()]\n",
    "best_results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.145774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_rf__n_estimators  mean_train_score  std_train_score  mean_test_score  \\\n",
       "11                     60               1.0              0.0              0.6   \n",
       "\n",
       "    std_test_score  \n",
       "11        0.145774  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among these results, select the result with the lowest number of estimators. \n",
    "best_result_rf = best_results_rf[best_results_rf.param_rf__n_estimators == best_results_rf.param_rf__n_estimators.min()]\n",
    "best_result_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get this number of estimators. \n",
    "best_param_rf = best_result_rf.param_rf__n_estimators.iloc[0]\n",
    "best_param_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', None), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_rf_optimal = Pipeline([\n",
    "    ('scaler', None),\n",
    "    ('rf', RandomForestClassifier(n_estimators = best_param_rf, max_depth = None, random_state = 0))\n",
    "])\n",
    "\n",
    "# Fit optimal random forest. \n",
    "pipe_rf_optimal.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the test score. \n",
    "test_score_rf = pipe_rf_optimal.score(X_te, y_te)\n",
    "test_score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Predictions and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'bad', 'neutral', 'neutral', 'bad', 'bad', 'neutral',\n",
       "       'good', 'neutral', 'neutral', 'neutral', 'good', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'bad', 'bad', 'good', 'good',\n",
       "       'neutral', 'neutral', 'bad', 'bad', 'neutral', 'bad', 'neutral',\n",
       "       'neutral', 'bad', 'bad', 'neutral', 'neutral', 'neutral',\n",
       "       'neutral', 'bad', 'good'], dtype='<U7')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the predictions. \n",
    "y_pred_rf = pipe_rf_optimal.predict(X_te)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_te</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_rf</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1        2        3    4    5        6     7        8   \\\n",
       "y_te       good  good  neutral  neutral  bad  bad     good  good  neutral   \n",
       "y_pred_rf   bad   bad  neutral  neutral  bad  bad  neutral  good  neutral   \n",
       "\n",
       "                9   ...       26       27   28   29       30       31  \\\n",
       "y_te       neutral  ...  neutral  neutral  bad  bad     good     good   \n",
       "y_pred_rf  neutral  ...  neutral  neutral  bad  bad  neutral  neutral   \n",
       "\n",
       "                32       33   34    35  \n",
       "y_te       neutral  neutral  bad   bad  \n",
       "y_pred_rf  neutral  neutral  bad  good  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the true and predicted target values. \n",
    "pred_comparison = pd.DataFrame([y_te, y_pred_rf], index = ['y_te', 'y_pred_rf']).T\n",
    "pred_comparison.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  good  neutral  bad\n",
       "True class                     \n",
       "good            3        6    3\n",
       "neutral         0       12    0\n",
       "bad             2        1    9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a Scikit-learn confusion matrix. \n",
    "confusion_matrix_rf = scikit_learn_confusion_matrix(y_te, y_pred_rf)\n",
    "confusion_matrix_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The random forest model performs better than the baseline of 33%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Support Vector Machine (SVM)**\n",
    "\n",
    "In the following cells, we **fine-tune, fit and compute predictions from a SVM model**. In order to fit the model, we must define the 'C' and 'gamma' parameters, which control respectively the complexity of the model and the general behavior of the RBF kernel. For the 'C' parameter, the default value is 1, therefore it seems relevant to explore the parameter space around this value. For the 'gamma' parameter of the RBF kernel, the default value is 'auto', and from the documentation we learn that this value corresponds to 1 / n_features, therefore it seems relevant to compute this value and explore the parameter space around it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Grid search with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the set of values to explore for the C parameter. \n",
    "c_values = np.logspace(-3, 3, num = 7)\n",
    "c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9061431913971105e-06"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the 'auto' value for the gamma parameter. \n",
    "auto_value = 1 / X.shape[1]\n",
    "auto_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auto', 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the set of values to explore for the gamma parameter. \n",
    "rounded_auto_value = 10 ** np.round(np.log10(auto_value))\n",
    "g_values = ['auto', \n",
    "            np.round(0.00001 * rounded_auto_value, decimals = 15),\n",
    "            np.round(0.0001 * rounded_auto_value, decimals = 15),\n",
    "            np.round(0.001 * rounded_auto_value, decimals = 15),\n",
    "            np.round(0.01 * rounded_auto_value, decimals = 15),\n",
    "            np.round(0.1 * rounded_auto_value, decimals = 15),\n",
    "            np.round(1 * rounded_auto_value, decimals = 15),\n",
    "            np.round(10 * rounded_auto_value, decimals = 15),\n",
    "            np.round(100 * rounded_auto_value, decimals = 15)]\n",
    "g_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'svm__kernel': ['rbf'], 'svm__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'svm__gamma': ['auto', 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001]}, {'svm__kernel': ['linear'], 'svm__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'svm__gamma': ['auto']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(random_state = 0))\n",
    "])\n",
    "\n",
    "# Create cross-validation object. \n",
    "grid_svm = [{\n",
    "        'svm__kernel': ['rbf'],\n",
    "        'svm__C': c_values,\n",
    "        'svm__gamma': g_values\n",
    "    }, {\n",
    "        'svm__kernel': ['linear'],\n",
    "        'svm__C': c_values,\n",
    "        'svm__gamma': ['auto']\n",
    "    }]\n",
    "grid_cv_svm = GridSearchCV(pipe_svm, grid_svm, cv = 5, return_train_score = True, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Fit SVM. \n",
    "grid_cv_svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_svm__kernel</th>\n",
       "      <th>param_svm__C</th>\n",
       "      <th>param_svm__gamma</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.040931</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.138444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.179892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.040931</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.138444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.179892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.040931</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.138444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.179892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.036681</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.085797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.138444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.154560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.031180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.079057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.138444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.170783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.155009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.960417</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.145774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.103414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.031180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.079057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.138444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.121906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.031180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>linear</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>linear</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_svm__kernel param_svm__C param_svm__gamma  mean_train_score  \\\n",
       "0                rbf        0.001             auto          0.733333   \n",
       "1                rbf        0.001            1e-10          0.597917   \n",
       "2                rbf        0.001            1e-09          0.597917   \n",
       "3                rbf        0.001            1e-08          0.597917   \n",
       "4                rbf        0.001            1e-07          0.597917   \n",
       "5                rbf        0.001            1e-06          0.629167   \n",
       "6                rbf        0.001            1e-05          0.991667   \n",
       "7                rbf        0.001           0.0001          1.000000   \n",
       "8                rbf        0.001            0.001          1.000000   \n",
       "9                rbf         0.01             auto          0.733333   \n",
       "10               rbf         0.01            1e-10          0.597917   \n",
       "11               rbf         0.01            1e-09          0.597917   \n",
       "12               rbf         0.01            1e-08          0.597917   \n",
       "13               rbf         0.01            1e-07          0.597917   \n",
       "14               rbf         0.01            1e-06          0.629167   \n",
       "15               rbf         0.01            1e-05          0.991667   \n",
       "16               rbf         0.01           0.0001          1.000000   \n",
       "17               rbf         0.01            0.001          1.000000   \n",
       "18               rbf          0.1             auto          0.733333   \n",
       "19               rbf          0.1            1e-10          0.597917   \n",
       "20               rbf          0.1            1e-09          0.597917   \n",
       "21               rbf          0.1            1e-08          0.597917   \n",
       "22               rbf          0.1            1e-07          0.597917   \n",
       "23               rbf          0.1            1e-06          0.629167   \n",
       "24               rbf          0.1            1e-05          0.991667   \n",
       "25               rbf          0.1           0.0001          1.000000   \n",
       "26               rbf          0.1            0.001          1.000000   \n",
       "27               rbf            1             auto          0.750000   \n",
       "28               rbf            1            1e-10          0.597917   \n",
       "29               rbf            1            1e-09          0.597917   \n",
       "..               ...          ...              ...               ...   \n",
       "40               rbf           10            1e-07          0.650000   \n",
       "41               rbf           10            1e-06          0.950000   \n",
       "42               rbf           10            1e-05          1.000000   \n",
       "43               rbf           10           0.0001          1.000000   \n",
       "44               rbf           10            0.001          1.000000   \n",
       "45               rbf          100             auto          1.000000   \n",
       "46               rbf          100            1e-10          0.597917   \n",
       "47               rbf          100            1e-09          0.597917   \n",
       "48               rbf          100            1e-08          0.650000   \n",
       "49               rbf          100            1e-07          0.960417   \n",
       "50               rbf          100            1e-06          1.000000   \n",
       "51               rbf          100            1e-05          1.000000   \n",
       "52               rbf          100           0.0001          1.000000   \n",
       "53               rbf          100            0.001          1.000000   \n",
       "54               rbf         1000             auto          1.000000   \n",
       "55               rbf         1000            1e-10          0.597917   \n",
       "56               rbf         1000            1e-09          0.650000   \n",
       "57               rbf         1000            1e-08          0.962500   \n",
       "58               rbf         1000            1e-07          1.000000   \n",
       "59               rbf         1000            1e-06          1.000000   \n",
       "60               rbf         1000            1e-05          1.000000   \n",
       "61               rbf         1000           0.0001          1.000000   \n",
       "62               rbf         1000            0.001          1.000000   \n",
       "63            linear        0.001             auto          1.000000   \n",
       "64            linear         0.01             auto          1.000000   \n",
       "65            linear          0.1             auto          1.000000   \n",
       "66            linear            1             auto          1.000000   \n",
       "67            linear           10             auto          1.000000   \n",
       "68            linear          100             auto          1.000000   \n",
       "69            linear         1000             auto          1.000000   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "0          0.040931         0.500000        0.091287  \n",
       "1          0.034611         0.566667        0.138444  \n",
       "2          0.034611         0.583333        0.170783  \n",
       "3          0.034611         0.583333        0.170783  \n",
       "4          0.034611         0.583333        0.170783  \n",
       "5          0.032676         0.600000        0.179892  \n",
       "6          0.004167         0.416667        0.114867  \n",
       "7          0.000000         0.333333        0.000000  \n",
       "8          0.000000         0.333333        0.000000  \n",
       "9          0.040931         0.500000        0.091287  \n",
       "10         0.034611         0.566667        0.138444  \n",
       "11         0.034611         0.583333        0.170783  \n",
       "12         0.034611         0.583333        0.170783  \n",
       "13         0.034611         0.583333        0.170783  \n",
       "14         0.032676         0.600000        0.179892  \n",
       "15         0.004167         0.416667        0.114867  \n",
       "16         0.000000         0.333333        0.000000  \n",
       "17         0.000000         0.333333        0.000000  \n",
       "18         0.040931         0.500000        0.091287  \n",
       "19         0.034611         0.566667        0.138444  \n",
       "20         0.034611         0.583333        0.170783  \n",
       "21         0.034611         0.583333        0.170783  \n",
       "22         0.034611         0.583333        0.170783  \n",
       "23         0.032676         0.600000        0.179892  \n",
       "24         0.004167         0.416667        0.114867  \n",
       "25         0.000000         0.333333        0.000000  \n",
       "26         0.000000         0.333333        0.000000  \n",
       "27         0.036681         0.475000        0.085797  \n",
       "28         0.034611         0.566667        0.138444  \n",
       "29         0.034611         0.583333        0.170783  \n",
       "..              ...              ...             ...  \n",
       "40         0.028413         0.616667        0.152297  \n",
       "41         0.010206         0.533333        0.154560  \n",
       "42         0.000000         0.366667        0.031180  \n",
       "43         0.000000         0.333333        0.000000  \n",
       "44         0.000000         0.333333        0.000000  \n",
       "45         0.000000         0.458333        0.079057  \n",
       "46         0.034611         0.566667        0.138444  \n",
       "47         0.034611         0.583333        0.170783  \n",
       "48         0.028413         0.608333        0.155009  \n",
       "49         0.010206         0.608333        0.145774  \n",
       "50         0.000000         0.533333        0.103414  \n",
       "51         0.000000         0.366667        0.031180  \n",
       "52         0.000000         0.333333        0.000000  \n",
       "53         0.000000         0.333333        0.000000  \n",
       "54         0.000000         0.458333        0.079057  \n",
       "55         0.034611         0.566667        0.138444  \n",
       "56         0.028413         0.616667        0.152297  \n",
       "57         0.008333         0.616667        0.121906  \n",
       "58         0.000000         0.558333        0.133333  \n",
       "59         0.000000         0.541667        0.114867  \n",
       "60         0.000000         0.366667        0.031180  \n",
       "61         0.000000         0.333333        0.000000  \n",
       "62         0.000000         0.333333        0.000000  \n",
       "63         0.000000         0.558333        0.122474  \n",
       "64         0.000000         0.558333        0.122474  \n",
       "65         0.000000         0.558333        0.122474  \n",
       "66         0.000000         0.558333        0.122474  \n",
       "67         0.000000         0.558333        0.122474  \n",
       "68         0.000000         0.558333        0.122474  \n",
       "69         0.000000         0.558333        0.122474  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results with a DataFrame. \n",
    "cv_results_svm = train_valid_dataframe(grid_cv_svm, 'svm', 'gamma', 'C', 'kernel')\n",
    "cv_results_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Test score with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rbf'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the maximum mean test score for the RBF and linear kernels. \n",
    "max_rbf = cv_results_svm.loc[cv_results_svm.param_svm__kernel == 'rbf', 'mean_test_score'].max()\n",
    "max_linear = cv_results_svm.loc[cv_results_svm.param_svm__kernel == 'linear', 'mean_test_score'].max()\n",
    "\n",
    "# If the kernels have different maximum mean test scores, select the best kernel. \n",
    "if max_rbf > max_linear:\n",
    "    best_kernel = 'rbf'\n",
    "elif max_rbf < max_linear:\n",
    "    best_kernel = 'linear'\n",
    "    \n",
    "# If both kernels have the same maximum mean test score, compute the average mean test score. \n",
    "elif max_rbf == max_linear:\n",
    "    mean_rbf = cv_results_svm.loc[cv_results_svm.param_svm__kernel == 'rbf', 'mean_test_score'].mean()\n",
    "    mean_linear = cv_results_svm.loc[cv_results_svm.param_svm__kernel == 'linear', 'mean_test_score'].mean()\n",
    "    \n",
    "    # If the kernels have different average mean test scores, select the best kernel. \n",
    "    # Otherwise select the RBF kernel, which is the default value for the SVC estimator. \n",
    "    if mean_rbf >= mean_linear:\n",
    "        best_kernel = 'rbf'\n",
    "    else:\n",
    "        best_kernel = 'linear'\n",
    "\n",
    "# Create a new DataFrame containing only the results from the best kernel. \n",
    "cv_results_best_kernel_svm = cv_results_svm[cv_results_svm.param_svm__kernel == best_kernel]\n",
    "\n",
    "# Display the best kernel. \n",
    "best_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_svm__kernel</th>\n",
       "      <th>param_svm__C</th>\n",
       "      <th>param_svm__gamma</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.121906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_svm__kernel param_svm__C param_svm__gamma  mean_train_score  \\\n",
       "40               rbf           10            1e-07            0.6500   \n",
       "56               rbf         1000            1e-09            0.6500   \n",
       "57               rbf         1000            1e-08            0.9625   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "40         0.028413         0.616667        0.152297  \n",
       "56         0.028413         0.616667        0.152297  \n",
       "57         0.008333         0.616667        0.121906  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among the results with the best kernel, select the results with the highest mean test score. \n",
    "best_results_svm = cv_results_best_kernel_svm[cv_results_best_kernel_svm.mean_test_score == cv_results_best_kernel_svm.mean_test_score.max()]\n",
    "best_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_svm__kernel</th>\n",
       "      <th>param_svm__C</th>\n",
       "      <th>param_svm__gamma</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.121906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_svm__kernel param_svm__C param_svm__gamma  mean_train_score  \\\n",
       "40               rbf           10            1e-07            0.6500   \n",
       "56               rbf         1000            1e-09            0.6500   \n",
       "57               rbf         1000            1e-08            0.9625   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "40         0.028413         0.616667        0.152297  \n",
       "56         0.028413         0.616667        0.152297  \n",
       "57         0.008333         0.616667        0.121906  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among these results, if some results show the standard parameter C = 1, select them. \n",
    "if np.sum(best_results_svm.param_svm__C == 1) > 0:\n",
    "    best_results_svm = best_results_svm[best_results_svm.param_svm__C == 1]\n",
    "best_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_svm__kernel</th>\n",
       "      <th>param_svm__C</th>\n",
       "      <th>param_svm__gamma</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.152297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.121906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_svm__kernel param_svm__C param_svm__gamma  mean_train_score  \\\n",
       "40               rbf           10            1e-07            0.6500   \n",
       "56               rbf         1000            1e-09            0.6500   \n",
       "57               rbf         1000            1e-08            0.9625   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "40         0.028413         0.616667        0.152297  \n",
       "56         0.028413         0.616667        0.152297  \n",
       "57         0.008333         0.616667        0.121906  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among these results, if some results show the standard parameter gamma = 'auto', select them. \n",
    "if np.sum(best_results_svm.param_svm__gamma == 'auto') > 0:\n",
    "    best_results_svm = best_results_svm[best_results_svm.param_svm__gamma == 'auto']\n",
    "best_results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_svm__kernel          rbf\n",
       "param_svm__C                10\n",
       "param_svm__gamma         1e-07\n",
       "mean_train_score          0.65\n",
       "std_train_score      0.0284129\n",
       "mean_test_score       0.616667\n",
       "std_test_score        0.152297\n",
       "Name: 40, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among the remaining results, select the first one. \n",
    "best_result_svm = best_results_svm.iloc[0]\n",
    "best_result_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C:     10.0\n",
      "Optimal gamma: 1e-07\n"
     ]
    }
   ],
   "source": [
    "# Get the parameters of this result. \n",
    "best_param_C_svm = best_result_svm.param_svm__C\n",
    "best_param_gamma_svm = best_result_svm.param_svm__gamma\n",
    "print('Optimal C:    ', best_param_C_svm)\n",
    "print('Optimal gamma:', best_param_gamma_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1e-07, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_svm_optimal = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel = best_kernel, C = best_param_C_svm, gamma = best_param_gamma_svm, random_state = 0))\n",
    "])\n",
    "\n",
    "# Fit optimal SVM. \n",
    "pipe_svm_optimal.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the test score. \n",
    "test_score_svm = pipe_svm_optimal.score(X_te, y_te)\n",
    "test_score_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Predictions and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'good', 'neutral', 'good', 'bad', 'bad', 'neutral', 'good',\n",
       "       'neutral', 'neutral', 'good', 'good', 'neutral', 'neutral',\n",
       "       'neutral', 'neutral', 'bad', 'bad', 'good', 'good', 'neutral',\n",
       "       'neutral', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad',\n",
       "       'neutral', 'good', 'neutral', 'neutral', 'bad', 'good'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the predictions. \n",
    "y_pred_svm = pipe_svm_optimal.predict(X_te)\n",
    "y_pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_te</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_svm</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1        2        3    4    5        6     7        8   \\\n",
       "y_te        good  good  neutral  neutral  bad  bad     good  good  neutral   \n",
       "y_pred_svm  good  good  neutral     good  bad  bad  neutral  good  neutral   \n",
       "\n",
       "                 9   ...       26       27   28   29       30    31       32  \\\n",
       "y_te        neutral  ...  neutral  neutral  bad  bad     good  good  neutral   \n",
       "y_pred_svm  neutral  ...      bad      bad  bad  bad  neutral  good  neutral   \n",
       "\n",
       "                 33   34    35  \n",
       "y_te        neutral  bad   bad  \n",
       "y_pred_svm  neutral  bad  good  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the true and predicted target values. \n",
    "pred_comparison = pd.DataFrame([y_te, y_pred_svm], index = ['y_te', 'y_pred_svm']).T\n",
    "pred_comparison.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  good  neutral  bad\n",
       "True class                     \n",
       "good            6        4    2\n",
       "neutral         1        9    2\n",
       "bad             3        0    9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a Scikit-learn confusion matrix. \n",
    "confusion_matrix_svm = scikit_learn_confusion_matrix(y_te, y_pred_svm)\n",
    "confusion_matrix_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The SVM model performs better than the baseline of 33%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Logistic regression**\n",
    "\n",
    "In the following cells, we **fine-tune, fit and compute predictions from a logistic regression model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Grid search with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the set of values to explore. \n",
    "c_values = np.logspace(-3, 3, num = 7)\n",
    "c_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed: 24.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'logreg__multi_class': ['ovr'], 'logreg__solver': ['liblinear'], 'logreg__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])}, {'logreg__multi_class': ['multinomial'], 'logreg__solver': ['saga'], 'logreg__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_logreg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(random_state = 0))\n",
    "])\n",
    "\n",
    "# Create cross-validation object. \n",
    "grid_logreg = [{\n",
    "        'logreg__multi_class': ['ovr'],\n",
    "        'logreg__solver': ['liblinear'],\n",
    "        'logreg__C': c_values\n",
    "    }, {\n",
    "        'logreg__multi_class': ['multinomial'],\n",
    "        'logreg__solver': ['saga'],\n",
    "        'logreg__C': c_values\n",
    "    }]\n",
    "grid_cv_logreg = GridSearchCV(pipe_logreg, grid_logreg, cv = 5, return_train_score = True, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Fit logistic regression. \n",
    "grid_cv_logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_logreg__multi_class</th>\n",
       "      <th>param_logreg__C</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ovr</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.104083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ovr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.106719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ovr</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.095015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ovr</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.095015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ovr</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.084984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ovr</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.097183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ovr</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.119606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_logreg__multi_class param_logreg__C  mean_train_score  \\\n",
       "0                        ovr           0.001               1.0   \n",
       "1                        ovr            0.01               1.0   \n",
       "2                        ovr             0.1               1.0   \n",
       "3                        ovr               1               1.0   \n",
       "4                        ovr              10               1.0   \n",
       "5                        ovr             100               1.0   \n",
       "6                        ovr            1000               1.0   \n",
       "7                multinomial           0.001               1.0   \n",
       "8                multinomial            0.01               1.0   \n",
       "9                multinomial             0.1               1.0   \n",
       "10               multinomial               1               1.0   \n",
       "11               multinomial              10               1.0   \n",
       "12               multinomial             100               1.0   \n",
       "13               multinomial            1000               1.0   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "0               0.0         0.558333        0.104083  \n",
       "1               0.0         0.575000        0.106719  \n",
       "2               0.0         0.583333        0.095015  \n",
       "3               0.0         0.583333        0.095015  \n",
       "4               0.0         0.575000        0.084984  \n",
       "5               0.0         0.608333        0.097183  \n",
       "6               0.0         0.616667        0.100000  \n",
       "7               0.0         0.608333        0.119606  \n",
       "8               0.0         0.616667        0.124722  \n",
       "9               0.0         0.616667        0.124722  \n",
       "10              0.0         0.616667        0.124722  \n",
       "11              0.0         0.616667        0.124722  \n",
       "12              0.0         0.616667        0.124722  \n",
       "13              0.0         0.616667        0.124722  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results with a DataFrame. \n",
    "cv_results_logreg = train_valid_dataframe(grid_cv_logreg, 'logreg', 'C', 'multi_class')\n",
    "cv_results_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Test score with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multinomial'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the maximum mean test score for the multinomial and OVR strategies. \n",
    "max_multinomial = cv_results_logreg.loc[cv_results_logreg.param_logreg__multi_class == 'multinomial', 'mean_test_score'].max()\n",
    "max_ovr = cv_results_logreg.loc[cv_results_logreg.param_logreg__multi_class == 'ovr', 'mean_test_score'].max()\n",
    "\n",
    "# If the strategies have different maximum mean test scores, select the best strategy. \n",
    "if max_multinomial > max_ovr:\n",
    "    best_strategy = 'multinomial'\n",
    "    best_solver = 'saga'\n",
    "elif max_multinomial < max_ovr:\n",
    "    best_strategy = 'ovr'\n",
    "    best_solver = 'liblinear'\n",
    "\n",
    "# If both strategies have the same maximum mean test score, compute the average mean test score. \n",
    "elif max_multinomial == max_ovr:\n",
    "    mean_multinomial = cv_results_logreg.loc[cv_results_logreg.param_logreg__multi_class == 'multinomial', 'mean_test_score'].mean()\n",
    "    mean_ovr = cv_results_logreg.loc[cv_results_logreg.param_logreg__multi_class == 'ovr', 'mean_test_score'].mean()\n",
    "    \n",
    "    # If the strategies have different average mean test scores, select the best strategy. \n",
    "    # Otherwise select the multinomial strategy, which is the 'auto' value for the LogisticRegression estimator when the data is not binary. \n",
    "    if mean_multinomial >= mean_ovr:\n",
    "        best_strategy = 'multinomial'\n",
    "        best_solver = 'saga'\n",
    "    else:\n",
    "        best_strategy = 'ovr'\n",
    "        best_solver = 'liblinear'\n",
    "\n",
    "# Create a new DataFrame containing only the results from the best strategy. \n",
    "cv_results_best_strategy_logreg = cv_results_logreg[cv_results_logreg.param_logreg__multi_class == best_strategy]\n",
    "\n",
    "# Display the best strategy. \n",
    "best_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_logreg__multi_class</th>\n",
       "      <th>param_logreg__C</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_logreg__multi_class param_logreg__C  mean_train_score  \\\n",
       "8                multinomial            0.01               1.0   \n",
       "9                multinomial             0.1               1.0   \n",
       "10               multinomial               1               1.0   \n",
       "11               multinomial              10               1.0   \n",
       "12               multinomial             100               1.0   \n",
       "13               multinomial            1000               1.0   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "8               0.0         0.616667        0.124722  \n",
       "9               0.0         0.616667        0.124722  \n",
       "10              0.0         0.616667        0.124722  \n",
       "11              0.0         0.616667        0.124722  \n",
       "12              0.0         0.616667        0.124722  \n",
       "13              0.0         0.616667        0.124722  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among the results with the best strategy, select the results with the highest mean test score. \n",
    "best_results_logreg = cv_results_best_strategy_logreg[cv_results_best_strategy_logreg.mean_test_score == cv_results_best_strategy_logreg.mean_test_score.max()]\n",
    "best_results_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_logreg__multi_class</th>\n",
       "      <th>param_logreg__C</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multinomial</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.124722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_logreg__multi_class param_logreg__C  mean_train_score  \\\n",
       "10               multinomial               1               1.0   \n",
       "\n",
       "    std_train_score  mean_test_score  std_test_score  \n",
       "10              0.0         0.616667        0.124722  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among these results, if some results show the standard parameter C = 1, select them. \n",
    "if np.sum(best_results_logreg.param_logreg__C == 1) > 0:\n",
    "    best_results_logreg = best_results_logreg[best_results_logreg.param_logreg__C == 1]\n",
    "best_results_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_logreg__multi_class    multinomial\n",
       "param_logreg__C                        1\n",
       "mean_train_score                       1\n",
       "std_train_score                        0\n",
       "mean_test_score                 0.616667\n",
       "std_test_score                  0.124722\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Among the remaining results, select the first one. \n",
    "best_result_logreg = best_results_logreg.iloc[0]\n",
    "best_result_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the C parameter. \n",
    "best_param_logreg = best_result_logreg.param_logreg__C\n",
    "best_param_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maeldonoso/opt/anaconda3/envs/exts-ml/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline. \n",
    "pipe_logreg_optimal = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(multi_class = best_strategy, solver = best_solver, C = best_param_logreg, random_state = 0))\n",
    "])\n",
    "\n",
    "# Fit optimal logistic regression. \n",
    "pipe_logreg_optimal.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055555555555556"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the test score. \n",
    "test_score_logreg = pipe_logreg_optimal.score(X_te, y_te)\n",
    "test_score_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Predictions, confusion matrix and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'good', 'neutral', 'neutral', 'bad', 'bad', 'good', 'good',\n",
       "       'neutral', 'neutral', 'bad', 'neutral', 'neutral', 'good',\n",
       "       'neutral', 'neutral', 'bad', 'bad', 'good', 'good', 'neutral',\n",
       "       'neutral', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'bad',\n",
       "       'bad', 'neutral', 'good', 'neutral', 'neutral', 'bad', 'bad'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute and display the predictions. \n",
    "y_pred_logreg = pipe_logreg_optimal.predict(X_te)\n",
    "y_pred_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_te</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred_logreg</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>...</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0     1        2        3    4    5     6     7        8   \\\n",
       "y_te           good  good  neutral  neutral  bad  bad  good  good  neutral   \n",
       "y_pred_logreg  good  good  neutral  neutral  bad  bad  good  good  neutral   \n",
       "\n",
       "                    9   ...       26       27   28   29       30    31  \\\n",
       "y_te           neutral  ...  neutral  neutral  bad  bad     good  good   \n",
       "y_pred_logreg  neutral  ...      bad      bad  bad  bad  neutral  good   \n",
       "\n",
       "                    32       33   34   35  \n",
       "y_te           neutral  neutral  bad  bad  \n",
       "y_pred_logreg  neutral  neutral  bad  bad  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the true and predicted target values. \n",
    "pred_comparison = pd.DataFrame([y_te, y_pred_logreg], index = ['y_te', 'y_pred_logreg']).T\n",
    "pred_comparison.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions  good  neutral  bad\n",
       "True class                     \n",
       "good            9        2    1\n",
       "neutral         0       10    2\n",
       "bad             1        1   10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a Scikit-learn confusion matrix. \n",
    "confusion_matrix_logreg = scikit_learn_confusion_matrix(y_te, y_pred_logreg)\n",
    "confusion_matrix_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we explore further the results from the logistic regression by analyzing, for every statistical map, the **probabilities computed for each target value**. In particular, we look at the predicted probability for the true target value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'good', 'neutral'], dtype='<U7')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and display the encoding order. \n",
    "encoding_order = np.unique(y_te)\n",
    "encoding_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>neutral</th>\n",
       "      <th>bad</th>\n",
       "      <th>y_pred_logreg</th>\n",
       "      <th>y_te</th>\n",
       "      <th>probability_of_true_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.9992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.9924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.3774</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.5951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7451</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.8311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4661</td>\n",
       "      <td>0.5336</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>0.4661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.8959</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.8959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3042</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.5671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.9986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.8493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.3641</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.6062</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>good</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.3932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.6517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>bad</td>\n",
       "      <td>good</td>\n",
       "      <td>0.1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.8346</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.8422</td>\n",
       "      <td>bad</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>neutral</td>\n",
       "      <td>good</td>\n",
       "      <td>0.3693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>0.8766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.8822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.4467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      good  neutral     bad y_pred_logreg     y_te  probability_of_true_value\n",
       "0   0.9942   0.0005  0.0053          good     good                     0.9942\n",
       "1   0.9942   0.0001  0.0058          good     good                     0.9942\n",
       "2   0.1846   0.7996  0.0158       neutral  neutral                     0.7996\n",
       "3   0.3844   0.4957  0.1199       neutral  neutral                     0.4957\n",
       "4   0.0008   0.0000  0.9992           bad      bad                     0.9992\n",
       "5   0.0076   0.0000  0.9924           bad      bad                     0.9924\n",
       "6   0.5951   0.3774  0.0275          good     good                     0.5951\n",
       "7   0.7451   0.1511  0.1038          good     good                     0.7451\n",
       "8   0.0065   0.9932  0.0003       neutral  neutral                     0.9932\n",
       "9   0.0077   0.9906  0.0017       neutral  neutral                     0.9906\n",
       "10  0.0467   0.1222  0.8311           bad      bad                     0.8311\n",
       "11  0.0423   0.5820  0.3757       neutral      bad                     0.3757\n",
       "12  0.4661   0.5336  0.0002       neutral     good                     0.4661\n",
       "13  0.8959   0.1038  0.0003          good     good                     0.8959\n",
       "14  0.0011   0.9989  0.0000       neutral  neutral                     0.9989\n",
       "15  0.0125   0.9873  0.0001       neutral  neutral                     0.9873\n",
       "16  0.2000   0.1018  0.6982           bad      bad                     0.6982\n",
       "17  0.3042   0.1287  0.5671           bad      bad                     0.5671\n",
       "18  0.9975   0.0024  0.0000          good     good                     0.9975\n",
       "19  0.9986   0.0013  0.0001          good     good                     0.9986\n",
       "20  0.1506   0.8493  0.0001       neutral  neutral                     0.8493\n",
       "21  0.0415   0.9585  0.0000       neutral  neutral                     0.9585\n",
       "22  0.3641   0.0006  0.6353           bad      bad                     0.6353\n",
       "23  0.6062   0.0007  0.3932          good      bad                     0.3932\n",
       "24  0.6517   0.0037  0.3446          good     good                     0.6517\n",
       "25  0.1955   0.0002  0.8043           bad     good                     0.1955\n",
       "26  0.1248   0.0406  0.8346           bad  neutral                     0.0406\n",
       "27  0.0837   0.0741  0.8422           bad  neutral                     0.0741\n",
       "28  0.0000   0.0000  1.0000           bad      bad                     1.0000\n",
       "29  0.0001   0.0000  0.9999           bad      bad                     0.9999\n",
       "30  0.3693   0.6304  0.0004       neutral     good                     0.3693\n",
       "31  0.8766   0.1225  0.0009          good     good                     0.8766\n",
       "32  0.0008   0.9991  0.0000       neutral  neutral                     0.9991\n",
       "33  0.0007   0.9993  0.0000       neutral  neutral                     0.9993\n",
       "34  0.0514   0.0665  0.8822           bad      bad                     0.8822\n",
       "35  0.2177   0.3356  0.4467           bad      bad                     0.4467"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the probabilities and convert them into a DataFrame with the appropriate column order. \n",
    "probabilities = np.round(pipe_logreg_optimal.predict_proba(X_te), 4)\n",
    "probabilities = pd.DataFrame(probabilities, columns = encoding_order)\n",
    "probabilities = probabilities[['good', 'neutral', 'bad']]\n",
    "\n",
    "# Add the predicted and true target values. \n",
    "probabilities['y_pred_logreg'] = y_pred_logreg\n",
    "probabilities['y_te'] = y_te\n",
    "\n",
    "# Compute the predicted probability for the true target value. \n",
    "for index in range(0, probabilities.shape[0]):\n",
    "    probabilities.loc[index, 'probability_of_true_value'] = probabilities.loc[index, y_te[index]]\n",
    "\n",
    "# Display the DataFrame. \n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the predicted probability for the true target value, sorted in ascending order. \n",
    "plt.scatter(range(0, probabilities.shape[0]), probabilities.probability_of_true_value.sort_values());\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Predicted probability for the true target value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The logistic regression model performs better than the baseline of 33%. Most of the time, the model predicts a high or intermediate probability for the true target value, but it fails for a few statistical maps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Save results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results into a .npz file. \n",
    "if rescale_mode == 1:\n",
    "    results_file_name = 'classification_results.npz'\n",
    "else:\n",
    "    results_file_name = 'classification_results_r' + str(rescale_mode) + '.npz'\n",
    "\n",
    "np.savez(results_path + results_file_name, \n",
    "         # Test scores. \n",
    "         test_score_knn = test_score_knn, \n",
    "         test_score_dt = test_score_dt, \n",
    "         test_score_rf = test_score_rf, \n",
    "         test_score_svm = test_score_svm, \n",
    "         test_score_logreg = test_score_logreg, \n",
    "         \n",
    "         # Predictions. \n",
    "         y_pred_knn = y_pred_knn, \n",
    "         y_pred_dt = y_pred_dt, \n",
    "         y_pred_rf = y_pred_rf, \n",
    "         y_pred_svm = y_pred_svm, \n",
    "         y_pred_logreg = y_pred_logreg, \n",
    "\n",
    "         # Target. \n",
    "         y_te = y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
